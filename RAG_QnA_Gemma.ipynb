{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XkGGFofL87"
      },
      "source": [
        "## **Approach :-**\n",
        "\n",
        "\n",
        "\n",
        "### 1.   **Document Loading** : Fetching Data Science Interview Questions from github\n",
        "### 2.   **Document Splitting** : The loaded document is split into smaller, manageable chunks to allow for efficient search and retrieval. This is done using a Recursive Character Text Splitter, which divides the document based on logical separators such as paragraphs, sentences, or characters. This ensures that each chunk contains coherent pieces of information.\n",
        "    The text is split into chunks of 1000 characters with a small overlap between them to maintain context across chunks.\n",
        "\n",
        "\n",
        "\n",
        "### 3.   **Embedding Generation** : The system uses HuggingFace Embeddings to transform each document chunk into a dense vector representation. These embeddings capture the semantic meaning of the text and allow for similarity-based retrieval.\n",
        "    The HuggingFace model generates vector embeddings for both the document chunks and the user queries.\n",
        "### 4.   **Vector Store with FAISS** : The embeddings are stored in a FAISS (Facebook AI Similarity Search) vector store, which enables fast, approximate similarity search. When a user issues a query, FAISS compares the query embedding to the stored document embeddings and retrieves the most similar chunks.\n",
        "    FAISS is highly efficient at handling large-scale vector searches, making it ideal for querying the document database.\n",
        "### 5. **Query Processing and Document Retrieval** : When a user inputs a query, the system transforms the query into an embedding using the same HuggingFace model. FAISS then performs a similarity search to retrieve document chunks that are most semantically relevant to the query.\n",
        "\n",
        "### 6. **Generative Response with GROQ Language Model** : When a user inputs a query, the system transforms the query into an embedding using the same HuggingFace model. FAISS then performs a similarity search to retrieve document chunks that are most semantically relevant to the query.\n",
        "    Note: Groq is used for faster inference\n",
        "\n",
        "## **RAG**:\n",
        "### **Retrieval:** The system retrieves relevant context (document chunks) using FAISS, which ensures the answer is grounded in the provided documents.\n",
        "###**Generation:** The GROQ LLM generates a coherent answer based on the retrieved context and the user’s query.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shQGSND64xE6"
      },
      "source": [
        "## Installing Dependencies and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncsEjTTN4acX",
        "outputId": "065540a6-879f-4315-eab4-1efc0563214c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.1/405.1 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.1/249.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.8/289.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain_core langchain_community sentence_transformers faiss-cpu chromadb langchain_groq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOBRO4RBuN-g"
      },
      "source": [
        "## Setting Up the GROQ API Key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEWN6vEB4p4z",
        "outputId": "19f6cdcc-5aeb-4ad3-ccb5-db55f77fda93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Provide your GROQ API TOKEN··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Provide your GROQ API TOKEN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZAqFpXhuaUJ"
      },
      "source": [
        "## Fetching Data Science Interview QnA Text Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lFAGpuCc48MX"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/youssefHosni/Data-Science-Interview-Questions-Answers/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md\"\n",
        "res = requests.get(url)\n",
        "with open(\"ds_interview_ques.txt\", \"w\") as f:\n",
        "  f.write(res.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BcE87DzH6sys"
      },
      "outputs": [],
      "source": [
        "# Document Loader\n",
        "from langchain.document_loaders import TextLoader\n",
        "loader = TextLoader('./ds_interview_ques.txt')\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abD-nLGF6wKM",
        "outputId": "6d7f1af6-15da-41ac-864b-5d4604228220"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './ds_interview_ques.txt'}, page_content='# Machine Learning Interview Questions & Answers for Data Scientists #\\n\\n## Questions ##\\n* [Q1: Mention three ways to make your model robust to outliers?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q1-mention-three-ways-to-make-your-model-robust-to-outliers)\\n* [Q2: Describe the motivation behind random forests and mention two reasons why they are better than individual decision trees?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q2-describe-the-motivation-behind-random-forests-and-mention-two-reasons-why-they-are-better-than-individual-decision-trees)\\n* [Q3: What are the differences and similarities between gradient boosting and random forest? and what are the advantages and disadvantages of each when compared to each other?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q3-what-are-the-differences-and-similarities-between-gradient-boosting-and-random-forest-and-what-are-the-advantage-and-disadvantages-of-each-when-compared-to-each-other)\\n* [Q4: What are L1 and L2 regularization? What are the differences between the two?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q4-what-are-l1-and-l2-regularization-what-are-the-differences-between-the-two)\\n* [Q5: What are the Bias and Variance in a Machine Learning Model and explain the bias-variance trade-off?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q5-what-are-the-bias-and-variance-in-a-machine-learning-model-and-explain-the-bias-variance-trade-off)\\n* [Q6: Mention three ways to handle missing or corrupted data in a dataset?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q6-mention-three-ways-to-handle-missing-or-corrupted-data-in-a-dataset)\\n* [Q7: Explain briefly the logistic regression model and state an example of when you have used it recently?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q7-explain-briefly-the-logistic-regression-model-and-state-an-example-of-when-you-have-used-it-recently)\\n* [Q8: Explain briefly batch gradient descent, stochastic gradient descent, and mini-batch gradient descent. and what are the pros and cons for each of them?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q8-explain-briefly-batch-gradient-descent-stochastic-gradient-descent-and-mini-batch-gradient-descent-and-what-are-the-pros-and-cons-for-each-of-them)\\n* [Q9: Explain what is information gain and entropy in the context of decision trees?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q9-explain-what-is-information-gain-and-entropy-in-the-context-of-decision-trees)\\n* [Q10: Explain the linear regression model and discuss its assumption?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q10-explain-the-linear-regression-model-and-discuss-its-assumption)\\n* [Q11: Explain briefly the K-Means clustering and how can we find the best value of K?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q11-explain-briefly-the-k-means-clustering-and-how-can-we-find-the-best-value-of-k)\\n* [Q12: Define Precision, recall, and F1 and discuss the trade-off between them?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q12-define-precision-recall-and-f1-and-discuss-the-trade-off-between-them)\\n* [Q13: What are the differences between a model that minimizes squared error and the one that minimizes the absolute error? and in which cases each error metric would be more appropriate?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q13-what-are-the-differences-between-a-model-that-minimizes-squared-error-and-the-one-that-minimizes-the-absolute-error-and-in-which-cases-each-error-metric-would-be-more-appropriate)\\n* [Q14: Define and compare parametric and non-parametric models and give two examples for each of them?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q14-define-and-compare-parametric-and-non-parametric-models-and-give-two-examples-for-each-of-them)\\n* [Q15: Explain the kernel trick in SVM and why we use it and how to choose what kernel to use?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q15-explain-the-kernel-trick-in-svm-and-why-we-use-it-and-how-to-choose-what-kernel-to-use)\\n* [Q16: Define the cross-validation process and the motivation behind using it?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q16-define-the-cross-validation-process-and-the-motivation-behind-using-it)\\n* [Q17: You are building a binary classifier and you found that the data is imbalanced, what should you do to handle this situation?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q17-you-are-building-a-binary-classifier-and-you-found-that-the-data-is-imbalanced-what-should-you-do-to-handle-this-situation)\\n* [Q18: You are working on a clustering problem, what are different evaluation metrics that can be used, and how to choose between them?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q18-you-are-working-on-a-clustering-problem-what-are-different-evaluation-metrics-that-can-be-used-and-how-to-choose-between-them)\\n* [Q19: What is the ROC curve and when should you use it?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q19-what-is-the-roc-curve-and-when-should-you-use-it)\\n* [Q20: What is the difference between hard and soft voting classifiers in the context of ensemble learners?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q20-what-is-the-difference-between-hard-and-soft-voting-classifiers-in-the-context-of-ensemble-learners)\\n* [Q21: What is boosting in the context of ensemble learners discuss two famous boosting methods](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q21-what-is-boosting-in-the-context-of-ensemble-learners-discuss-two-famous-boosting-methods)\\n* [Q22: How can you evaluate the performance of a dimensionality reduction algorithm on your dataset?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q22-how-can-you-evaluate-the-performance-of-a-dimensionality-reduction-algorithm-on-your-dataset)\\n* [Q23: Define the curse of dimensionality and how to solve it. ](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q23-define-the-curse-of-dimensionality-and-how-to-solve-it)\\n* [Q24: In what cases would you use vanilla PCA, Incremental PCA, Randomized PCA, or Kernel PCA?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q24-in-what-cases-would-you-use-vanilla-pca-incremental-pca-randomized-pca-or-kernel-pca)\\n* [Q25: Discuss two clustering algorithms that can scale to large datasets](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q25-discuss-two-clustering-algorithms-that-can-scale-to-large-datasets)\\n* [Q26: Do you need to scale your data if you will be using the SVM classifier and discuss your answer](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q26-do-you-need-to-scale-your-data-if-you-will-be-using-the-svm-classifier-and-discus-your-answer)\\n* [Q27: What are Loss Functions and Cost Functions? Explain the key Difference Between them.](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q27-what-are-loss-functions-and-cost-functions-explain-the-key-difference-between-them)\\n* [Q28: What is the importance of batch in machine learning and explain some batch depend on gradient descent algorithm?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q28-what-is-the-importance-of-batch-in-machine-learning-and-explain-some-batch-depend-gradient-descent-algorithm)\\n* [Q29: What are the different methods to split a tree in a decision tree algorithm?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q29-what-are-the-different-methods-to-split-a-tree-in-a-decision-tree-algorithm)\\n* [Q30: Why boosting is a more stable algorithm as compared to other ensemble algorithms? ](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q30-why-boosting-is-a-more-stable-algorithm-as-compared-to-other-ensemble-algorithms)\\n* [Q31: What is active learning and discuss one strategy of it?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q31-what-is-active-learning-and-discuss-one-strategy-of-it)\\n* [Q32: What are the different approaches to implementing recommendation systems?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20&%20Answers%20for%20Data%20Scientists.md#:~:text=the%20best%20instances.-,Q32%3A%20What%20are%20the%20different%20approaches%20to%20implementing%20recommendation%20systems%3F,-Answer%3A)\\n* [Q33: What are the evaluation metrics that can be used for multi-label classification?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20&%20Answers%20for%20Data%20Scientists.md#:~:text=Q33%3A%20What%20are%20the%20evaluation%20metrics%20that%20can%20be%20used%20for%20multi%2Dlabel%20classification%3F)\\n* [Q34: What is the difference between concept and data drift and how to overcome each of them?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20&%20Answers%20for%20Data%20Scientists.md#:~:text=at%20k%20(MAP%40k)-,Q34%3A%20What%20is%20the%20difference%20between%20concept%20and%20data%20drift%20and%20how%20to%20overcome%20each%20of%20them%3F,-Answer%3A)\\n* [Q35: Can you explain the ARIMA model and its components?]()\\n* [Q36: What are the assumptions made by the ARIMA model?]()\\n\\n-------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n## Questions & Answers ##\\n\\n### Q1: Mention three ways to make your model robust to outliers. ###\\n\\nInvestigating the outliers is always the first step in understanding how to treat them. After you understand the nature of why the outliers occurred you can apply one of the several methods mentioned [here](https://365datascience.com/career-advice/job-interview-tips/machine-learning-interview-questions-and-answers/#11:~:text=for%20large%20datasets.-,Bonus%20Question%3A%20Discuss%20how%20to%20make%20your%20model%20robust%20to%20outliers.,-There%20are%20several).\\n\\n### Q2: Describe the motivation behind random forests and mention two reasons why they are better than individual decision trees. ###\\n\\nThe motivation behind random forest or ensemble models in general in layman\\'s terms, Let\\'s say we have a question/problem to solve we bring 100 people and ask each of them the question/problem and record their solution. The rest of the answer is [here](https://365datascience.com/career-advice/job-interview-tips/machine-learning-interview-questions-and-answers/#2:~:text=2.%20Describe%20the%20motivation%20behind%20random%20forests%20and%20mention%20two%20reasons%20why%20they%20are%20better%20than%20individual%20decision%C2%A0trees.)\\n\\n### Q3: What are the differences and similarities between gradient boosting and random forest? and what are the advantages and disadvantages of each when compared to each other? ###\\n\\nSimilarities:\\n1. Both these algorithms are decision-tree-based algorithms\\n2. Both these algorithms are ensemble algorithms\\n3. Both are flexible models and do not need much data preprocessing.\\n\\nThe rest of the answer is [here](https://365datascience.com/career-advice/job-interview-tips/machine-learning-interview-questions-and-answers/#2:~:text=3.%20What%20are%20the%20differences%20and%20similarities%20between%20gradient%20boosting%20and%20random%20forest%3F%20And%20what%20are%20the%20advantages%20and%20disadvantages%20of%20each%20when%20compared%20to%20each%C2%A0other%3F)\\n\\n### Q4: What are L1 and L2 regularization? What are the differences between the two? ###\\n\\nAnswer:\\n\\nRegularization is a technique used to avoid overfitting by trying to make the model more simple.The rest of the answer is [here](https://365datascience.com/career-advice/job-interview-tips/machine-learning-interview-questions-and-answers/#2:~:text=6.%20What%20are%20L1%20and%20L2%20regularizations%3F%20What%20are%20the%20differences%20between%20the%C2%A0two%3F)\\n### Q5: What are the Bias and Variance in a Machine Learning Model and explain the bias-variance trade-off? ###\\n\\nAnswer:\\n\\nThe goal of any supervised machine learning model is to estimate the mapping function (f) that predicts the target variable (y) given input (x). The prediction error can be broken down into three parts:\\nThe rest of the answer is [here](https://365datascience.com/career-advice/job-interview-tips/machine-learning-interview-questions-and-answers/#2:~:text=8.%20What%20are%20the%20bias%20and%20variance%20in%20a%20machine%20learning%20model%20and%20explain%20the%20bias%2Dvariance%20trade%2Doff%3F)\\n\\n### Q6: Mention three ways to handle missing or corrupted data in a dataset. ###\\n\\nAnswer:\\n\\nIn general, real-world data often has a lot of missing values. The cause of missing values can be data corruption or failure to record data. The rest of the answer is [here](https://365datascience.com/career-advice/job-interview-tips/machine-learning-interview-questions-and-answers/#9:~:text=10.-,Mention%20three%20ways%20to%20handle%20missing%20or%20corrupted%20data%20in%20a%C2%A0dataset.,-In%20general%2C%20real)\\n\\n### Q7: Explain briefly the logistic regression model and state an example of when you have used it recently. ###\\n\\nAnswer:\\n\\nLogistic regression is used to calculate the probability of occurrence of an event in the form of a dependent output variable based on independent input variables. Logistic regression is commonly used to estimate the probability that an instance belongs to a particular class. If the probability is bigger than 0.5 then it will belong to that class (positive) and if it is below 0.5 it will belong to the other class. This will make it a binary classifier.\\n\\nIt is important to remember that the Logistic regression isn\\'t a classification model, it\\'s an ordinary type of regression algorithm, and it was developed and used before machine learning, but it can be used in classification when we put a threshold to determine specific categories\"\\n\\nThere is a lot of classification applications to it:\\n\\nClassify email as spam or not, To identify whether the patient is healthy or not, and so on.\\n\\n### Q8: Explain briefly batch gradient descent, stochastic gradient descent, and mini-batch gradient descent. and what are the pros and cons for each of them? ###\\n\\nGradient descent is a generic optimization algorithm cable for finding optimal solutions to a wide range of problems. The general idea of gradient descent is to tweak parameters iteratively in order to minimize a cost function.\\n\\nBatch Gradient Descent:\\nIn Batch Gradient descent the whole training data is used to minimize the loss function by taking a step toward the nearest minimum by calculating the gradient (the direction of descent)\\n\\nPros:\\nSince the whole data set is used to calculate the gradient it will be stable and reach the minimum of the cost function without bouncing (if the learning rate is chosen cooreclty)\\n\\nCons:\\n\\nSince batch gradient descent uses all the training set to compute the gradient at every step, it will be very slow especially if the size of the training data is large.\\n\\n\\nStochastic Gradient Descent:\\n\\nStochastic Gradient Descent picks up a random instance in the training data set at every step and computes the gradient based only on that single instance.\\n\\nPros:\\n1. It makes the training much faster as it only works on one instance at a time.\\n2. It become easier to train large datasets\\n\\nCons:\\n\\nDue to the stochastic (random) nature of this algorithm, this algorithm is much less regular than the batch gradient descent. Instead of gently decreasing until it reaches the minimum, the cost function will bounce up and down, decreasing only on average. Over time it will end up very close to the minimum, but once it gets there it will continue to bounce around, not settling down there. So once the algorithm stops the final parameters are good but not optimal. For this reason, it is important to use a training schedule to overcome this randomness.\\n\\nMini-batch Gradient:\\n\\nAt each step instead of computing the gradients on the whole data set as in the Batch Gradient Descent or using one random instance as in the Stochastic Gradient Descent, this algorithm computes the gradients on small random sets of instances called mini-batches.\\n\\nPros: \\n1. The algorithm\\'s progress space is less erratic than with Stochastic Gradient Descent, especially with large mini-batches.\\n2. You can get a performance boost from hardware optimization of matrix operations, especially when using GPUs.\\n\\nCons: \\n1. It might be difficult to escape from local minima.\\n\\n![alt text](https://github.com/youssefHosni/Data-Science-Interview-Questions/blob/main/Figures/gradient%20descent%20vs%20batch%20gradient%20descent.png)\\n\\n### Q9: Explain what is information gain and entropy in the context of decision trees. ###\\nEntropy and Information Gain are two key metrics used in determining the relevance of decision-making when constructing a decision tree model and determining the nodes and the best way to split.\\n\\nThe idea of a decision tree is to divide the data set into smaller data sets based on the descriptive features until we reach a small enough set that contains data points that fall under one label.\\n\\nEntropy is the measure of impurity, disorder, or uncertainty in a bunch of examples. Entropy controls how a Decision Tree decides to split the data.\\nInformation gain calculates the reduction in entropy or surprise from transforming a dataset in some way. It is commonly used in the construction of decision trees from a training dataset, by evaluating the information gain for each variable and selecting the variable that maximizes the information gain, which in turn minimizes the entropy and best splits the dataset into groups for effective classification.\\n\\n### Q10: Explain the linear regression model and discuss its assumption. ###\\nLinear regression is a supervised statistical model to predict dependent variable quantity based on independent variables.\\nLinear regression is a parametric model and the objective of linear regression is that it has to learn coefficients using the training data and predict the target value given only independent values.\\n\\nSome of the linear regression assumptions and how to validate them:\\n\\n1. Linear relationship between independent and dependent variables\\n2. Independent residuals and the constant residuals at every x\\nWe can check for 1 and 2 by plotting the residuals(error terms) against the fitted values (upper left graph). Generally, we should look for a lack of patterns and a consistent variance across the horizontal line.\\n3. Normally distributed residuals\\nWe can check for this using a couple of methods:\\n* Q-Q-plot(upper right graph): If data is normally distributed, points should roughly align with the 45-degree line.\\n* Boxplot: it also helps visualize outliers\\n* Shapiro–Wilk test: If the p-value is lower than the chosen threshold, then the null hypothesis (Data is normally distributed) is rejected.\\n4. Low multicollinearity\\n* you can calculate the VIF (Variable Inflation Factors) using your favorite statistical tool. If the value for each covariate is lower than 10 (some say 5), you\\'re good to go.\\n\\nThe figure below summarizes these assumptions.\\n![alt text](https://github.com/youssefHosni/Data-Science-Interview-Questions/blob/main/Figures/Linear%20regression%20assumptions.jpg)\\n\\n### Q11: Explain briefly the K-Means clustering and how can we find the best value of K? ###\\nK-Means is a well-known clustering algorithm. K-means clustering is often used because it is easy to interpret and implement. The rest of the answer is [here](https://365datascience.com/career-advice/job-interview-tips/machine-learning-interview-questions-and-answers/#2:~:text=4.%20Briefly%20explain%20the%20K%2DMeans%20clustering%20and%20how%20can%20we%20find%20the%20best%20value%20of%C2%A0K.)\\n\\n### Q12: Define Precision, recall, and F1 and discuss the trade-off between them? ###\\n\\nPrecision and recall are two classification evaluation metrics that are used beyond accuracy. The rest of the answer is [here](https://365datascience.com/career-advice/job-interview-tips/machine-learning-interview-questions-and-answers/#9:~:text=9.-,Define%20precision%2C%20recall%2C%20and%20F1%20and%20discuss%20the%20trade%2Doff%20between%C2%A0them.,-Precision%20and%20recall)\\n\\n### Q13: What are the differences between a model that minimizes squared error and the one that minimizes the absolute error? and in which cases each error metric would be more appropriate? ###\\n\\nBoth mean square error (MSE) and mean absolute error (MAE) measures the distances between vectors and express average model prediction in units of the target variable. Both can range from 0 to infinity, the lower they are the better the model.\\n\\nThe main difference between them is that in MSE the errors are squared before being averaged while in MAE they are not. This means that a large weight will be given to large errors. MSE is useful when large errors in the model are trying to be avoided. This means that outliers affect MSE more than MAE, that is why MAE is more robust to outliers. \\nComputation-wise MSE is easier to use as the gradient calculation will be more straightforward than MAE, which requires linear programming to calculate it.\\n\\n### Q14: Define and compare parametric and non-parametric models and give two examples for each of them? ###\\n\\nAnswer:\\n\\n**Parametric models** assume that the dataset comes from a certain function with some set of parameters that should be tuned to reach the optimal performance. For such models, the number of parameters is determined prior to training, thus the degree of freedom is limited and reduces the chances of overfitting.\\n\\nEx. Linear Regression, Logistic Regression, LDA\\n\\n**Nonparametric models** don\\'t assume anything about the function from which the dataset was sampled. For these models, the number of parameters is not determined prior to training, thus they are free to generalize the model based on the data. Sometimes these models overfit themselves while generalizing. To generalize they need more data in comparison with Parametric Models. They are relatively more difficult to interpret compared to Parametric Models.\\n\\nEx. Decision Tree, Random Forest.\\n\\n### Q15: Explain the kernel trick in SVM. Why do we use it and how to choose what kernel to use? ###\\nAnswer:\\nKernels are used in SVM to map the original input data into a particular higher dimensional space where it will be easier to find patterns in the data and train the model with better performance.\\n\\nFor eg.: If we have binary class data which form a ring-like pattern (inner and outer rings representing two different class instances) when plotted in 2D space, a linear SVM kernel will not be able to differentiate the two classes well when compared to an RBF (radial basis function) kernel, mapping the data into a particular higher dimensional space where the two classes are clearly separable.\\n\\nTypically without the kernel trick, in order to calculate support vectors and support vector classifiers, we need first to transform data points one by one to the higher dimensional space, do the calculations based on SVM equations in the higher dimensional space, and then return the results. The ‘trick’ in the kernel trick is that we design the kernels based on some conditions as mathematical functions that are equivalent to a dot product in the higher dimensional space without even having to transform data points to the higher dimensional space. i.e. we can calculate support vectors and support vector classifiers in the same space where the data is provided which saves a lot of time and calculations.\\n\\nHaving domain knowledge can be very helpful in choosing the optimal kernel for your problem, however, in the absence of such knowledge following this default rule can be helpful:\\nFor linear problems, we can try linear or logistic kernels, and for nonlinear problems, we can use RBF or Gaussian kernels.\\n\\n![Alt_text](https://github.com/youssefHosni/Data-Science-Interview-Questions/blob/main/Figures/Kerenl%20trick.png)\\n\\n### Q16: Define the cross-validation process and the motivation behind using it. ###\\nCross-validation is a technique used to assess the performance of a learning model in several subsamples of training data. In general, we split the data into train and test sets where we use the training data to train our model and the test data to evaluate the performance of the model on unseen data and validation set for choosing the best hyperparameters. Now, a random split in most cases(for large datasets) is fine. However, for smaller datasets, it is susceptible to loss of important information present in the data in which it was not trained. Hence, cross-validation though computationally expensive combats this issue.\\n\\nThe process of cross-validation is as follows:\\n\\n1. Define k or the number of folds\\n2. Randomly shuffle the data into K equally-sized blocks (folds)\\n3. For each i in fold 1 to k train the data using all the folds except for fold i and test on the fold i.\\n3. Average the K validation/test error from the previous step to get an estimate of the error.\\n\\nThis process aims to accomplish the following:\\n1- Prevent overfitting during training by avoiding training and testing on the same subset of the data points\\n\\n2- Avoid information loss by using a certain subset of the data for validation only. This is important for small datasets.\\n\\nCross-validation is always good to be used for small datasets, and if used for large datasets the computational complexity will increase depending on the number of folds.\\n\\n![Alt_text](https://github.com/youssefHosni/Data-Science-Interview-Questions/blob/main/Figures/cross%20validation.png)\\n\\n### Q17: You are building a binary classifier and you found that the data is imbalanced, what should you do to handle this situation? ###\\nAnswer:\\nIf there is a data imbalance there are several measures we can take to train a fairer binary classifier:\\n\\n**1. Pre-Processing:**\\n\\n* Check whether you can get more data or not.\\n\\n* Use sampling techniques (Sample minority class, Downsample majority class, can take the hybrid approach as well). We can also use data augmentation to add more data points for the minority class but with little deviations/changes leading to new data points that are similar to the ones they are derived from. The most common/popular technique is SMOTE (Synthetic Minority Oversampling technique)\\n\\n* Suppression: Though not recommended, we can drop off some features directly responsible for the imbalance.\\n\\n* Learning Fair Representation: Projecting the training examples to a subspace or plane minimizes the data imbalance.\\n\\n* Re-Weighting: We can assign some weights to each training example to reduce the imbalance in the data.\\n\\n**2. In-Processing:**\\n\\n* Regularisation: We can add score terms that measure the data imbalance in the loss function and therefore minimizing the loss function will also minimize the degree of imbalance concerning the score chosen which also indirectly minimizes other metrics that measure the degree of data imbalance.\\n\\n* Adversarial Debiasing: Here we use the adversarial notion to train the model where the discriminator tries to detect if there are signs of data imbalance in the predicted data by the generator and hence the generator learns to generate data that is less prone to imbalance.\\n\\n**3. Post-Processing:**\\n* Odds-Equalization: Here we try to equalize the odds for the classes with respect to the data is imbalanced for correct imbalance in the trained model. Usually, the F1 score is a good choice, if both precision and recall scores are important\\n\\n* Choose appropriate performance metrics. For example, accuracy is not a correct metric to use when classes are imbalanced. Instead, use precision, recall, F1 score, and ROC curve.\\n\\n![Alt_text](https://github.com/youssefHosni/Data-Science-Interview-Questions/blob/main/Figures/Oversampling.png)\\n\\n### Q18: You are working on a clustering problem, what are different evaluation metrics that can be used, and how to choose between them? ###\\n\\nAnswer:\\n\\nClusters are evaluated based on some similarity or dissimilarity measure such as the distance between cluster points. If the clustering algorithm separates dissimilar observations and similar observations together, then it has performed well. The two most popular metrics evaluation metrics for clustering algorithms are the 𝐒𝐢𝐥𝐡𝐨𝐮𝐞𝐭𝐭𝐞 𝐜𝐨𝐞𝐟𝐟𝐢𝐜𝐢𝐞𝐧𝐭 and 𝐃𝐮𝐧𝐧’𝐬 𝐈𝐧𝐝𝐞𝐱.\\n\\n𝐒𝐢𝐥𝐡𝐨𝐮𝐞𝐭𝐭𝐞 𝐜𝐨𝐞𝐟𝐟𝐢𝐜𝐢𝐞𝐧𝐭\\nThe Silhouette Coefficient is defined for each sample and is composed of two scores:\\na: The mean distance between a sample and all other points in the same cluster.\\nb: The mean distance between a sample and all other points in the next nearest cluster.\\n\\nS = (b-a) / max(a,b)\\n\\nThe 𝐒𝐢𝐥𝐡𝐨𝐮𝐞𝐭𝐭𝐞 𝐜𝐨𝐞𝐟𝐟𝐢𝐜𝐢𝐞𝐧𝐭 for a set of samples is given as the mean of the Silhouette Coefficient for each sample. The score is bounded between -1 for incorrect clustering and +1 for highly dense clustering. Scores around zero indicate overlapping clusters. The score is higher when clusters are dense and well separated, which relates to a standard concept of a cluster.\\n\\nDunn’s Index\\n\\nDunn’s Index (DI) is another metric for evaluating a clustering algorithm. Dunn’s Index is equal to the minimum inter-cluster distance divided by the maximum cluster size. Note that large inter-cluster distances (better separation) and smaller cluster sizes (more compact clusters) lead to a higher DI value. A higher DI implies better clustering. It assumes that better clustering means that clusters are compact and well-separated from other clusters.\\n\\n![Alt_text](https://github.com/youssefHosni/Data-Science-Interview-Questions/blob/main/Figures/Derivation-of-the-Overall-Silhouette-Coefficient-OverallSil.png)\\n\\n### Q19: What is the ROC curve and when should you use it? ### \\n\\nAnswer:\\n\\nROC curve, Receiver Operating Characteristic curve, is a graphical representation of the model\\'s performance where we plot the True Positive Rate (TPR) against the False Positive Rate (FPR) for different threshold values, for hard classification, between 0 to 1 based on model output.\\n\\nThis ROC curve is mainly used to compare two or more models as shown in the figure below. Now, it is easy to see that a reasonable model will always give FPR less (since it\\'s an error) than TPR so, the curve hugs the upper left corner of the square box 0 to 1 on the TPR axis and 0 to 1 on the FPR axis.\\n\\nThe more the AUC(area under the curve) for a model\\'s ROC curve, the better the model in terms of prediction accuracy in terms of TPR and FPR.\\n\\nHere are some benefits of using the ROC Curve :\\n\\n* Can help prioritize either true positives or true negatives depending on your case study (Helps you visually choose the best hyperparameters for your case)\\n\\n* Can be very insightful when we have unbalanced datasets\\n\\n* Can be used to compare different ML models by calculating the area under the ROC curve (AUC)\\n\\n![Alt_text](https://github.com/youssefHosni/Data-Science-Interview-Questions/blob/main/Figures/Roc_curve.svg.png)\\n\\n### Q20: What is the difference between hard and soft voting classifiers in the context of ensemble learners? ###\\n\\nAnswer:\\n\\n* Hard Voting: We take into account the class predictions for each classifier and then classify an input based on the maximum votes to a particular class.\\n\\n* Soft Voting: We take into account the probability predictions for each class by each classifier and then classify an input to the class with maximum probability based on the average probability (averaged over the classifier\\'s probabilities) for that class.\\n\\n![Alt_text](https://github.com/youssefHosni/Data-Science-Interview-Questions/blob/main/Figures/Hard%20Vs%20soft%20voting.png)\\n\\n### Q21: What is boosting in the context of ensemble learners discuss two famous boosting methods ###\\n\\nAnswer:\\n\\nBoosting refers to any Ensemble method that can combine several weak learners into a strong learner. The general idea of most boosting methods is to train predictors sequentially, each trying to correct its predecessor.\\n\\nThere are many boosting methods available, but by far the most popular are: \\n\\n* Adaptive Boosting: One way for a new predictor to correct its predecessor is to pay a bit more attention to the training instances that the predecessor under-fitted. This results in new predictors focusing more and more on the hard cases.\\n* Gradient Boosting:  Another very popular Boosting algorithm is Gradient Boosting. Just like AdaBoost, Gradient Boosting works by sequentially adding predictors to an ensemble, each one correcting its predecessor. However, instead of tweaking the instance weights at every iteration as AdaBoost does, this method tries to fit the new predictor to the residual errors made by the previous predictor.\\n\\n![1661788022018](https://user-images.githubusercontent.com/72076328/187241588-6cc3166f-a3e0-46b9-a0ce-e3d9ef9f0228.jpg)\\n\\n### Q22: How can you evaluate the performance of a dimensionality reduction algorithm on your dataset? ###\\n\\nAnswer:\\n\\nIntuitively, a dimensionality reduction algorithm performs well if it eliminates a lot of dimensions from the dataset without losing too much information. One way to measure this is to apply the reverse transformation and measure the reconstruction error. However, not all dimensionality reduction algorithms provide a reverse transformation.\\n\\nAlternatively, if you are using dimensionality reduction as a preprocessing step before another Machine Learning algorithm (e.g., a Random Forest classifier), then you can simply measure the performance of that second algorithm; if dimensionality reduction did not lose too much information, then the algorithm should perform just as well as when using the original dataset.\\n\\n### Q23: Define the curse of dimensionality and how to solve it. ###\\n\\nAnswer:\\nCurse of dimensionality represents the situation when the amount of data is too few to be represented in a high-dimensional space, as it will be highly scattered in that high-dimensional space and it becomes more probable that we overfit this data. If we increase the number of features, we are implicitly increasing model complexity and if we increase model complexity we need more data. \\n\\nPossible solutions are:\\nRemove irrelevant features not discriminating classes correlated or features not resulting in much improvement, we can use:\\n\\n* Feature selection(select the most important ones).\\n* Feature extraction(transform current feature dimensionality into a lower dimension preserving the most possible amount of information like PCA ).\\n\\n![Curse of dim\\'](https://user-images.githubusercontent.com/72076328/188653089-8999ea59-9511-4d52-baff-15a652e117a9.png)\\n\\n### Q24: In what cases would you use vanilla PCA, Incremental PCA, Randomized PCA, or Kernel PCA? ### \\n\\n\\nAnswer:\\n\\nRegular PCA is the default, but it works only if the dataset fits in memory. Incremental PCA is useful for large datasets that don\\'t fit in memory, but it is slower than regular PCA, so if the dataset fits in memory you should prefer regular PCA. Incremental PCA is also useful for online tasks when you need to apply PCA on the fly, every time a new instance arrives. Randomized PCA is useful when you want to considerably reduce dimensionality and the dataset fits in memory; in this case, it is much faster than regular PCA. Finally, Kernel PCA is useful for nonlinear datasets.\\n\\n\\n### Q25: Discuss two clustering algorithms that can scale to large datasets ###\\n\\nAnswer:\\n\\n**Minibatch Kmeans:**  Instead of using the full dataset at each iteration, the algorithm\\nis capable of using mini-batches, moving the centroids just slightly at each iteration.\\nThis speeds up the algorithm typically by a factor of 3 or 4 and makes it\\npossible to cluster huge datasets that do not fit in memory. Scikit-Learn implements\\nthis algorithm in the MiniBatchKMeans class.\\n\\n**Balanced Iterative Reducing and Clustering using Hierarchies (BIRCH)**\\xa0\\nis a clustering algorithm that can cluster large datasets by first generating a small and compact summary of the large dataset that retains as much information as possible. This smaller summary is then clustered instead of clustering the larger dataset.\\n\\n### Q26: Do you need to scale your data if you will be using the SVM classifier and discus your answer ###\\nAnswer:\\nYes, feature scaling is required for SVM and all margin-based classifiers since the optimal hyperplane (the decision boundary) is dependent on the scale of the input features. In other words, the distance between two observations will differ for scaled and non-scaled cases, leading to different models being generated. \\n\\nThis can be seen in the figure below, when the features have different scales, we can see that the decision boundary and the support vectors are only classifying the X1 features without taking into consideration the X0 feature, however after scaling the data to the same scale the decision boundaries and support vectors are looking much better and the model is taking into account both features.\\n\\nTo scale the data, normalization, and standardization are the most popular approaches.\\n![SVM scaled Vs non scaled](https://user-images.githubusercontent.com/72076328/192571498-4a939472-7bb1-4bf2-963f-a6e6394802ba.png)\\n\\n### Q27: What are Loss Functions and Cost Functions? Explain the key Difference Between them. ###\\n\\nAnswer:\\nThe loss function is the measure of the performance of the model on a single training example, whereas the cost function is the average loss function over all training examples or across the batch in the case of mini-batch gradient descent.\\n\\nSome examples of loss functions are Mean Squared Error, Binary Cross Entropy, etc.\\n\\nWhereas, the cost function is the average of the above loss functions over training examples.\\n\\n### Q28: What is the importance of batch in machine learning and explain some batch-dependent gradient descent algorithms? ###\\n\\nAnswer:\\nIn the memory, the dataset can load either completely at once or in the form of a set. If we have a huge size of the dataset, then loading the whole data into memory will reduce the training speed, hence batch term is introduced.\\n\\nExample: image data contains 1,00,000 images, we can load this into 3125 batches where 1 batch = 32 images. So instead of loading the whole 1,00,000 images in memory, we can load 32 images 3125 times which requires less memory.\\n\\nIn summary, a batch is important in two ways: (1) Efficient memory consumption. (2) Improve training speed.\\n\\nThere are 3 types of gradient descent algorithms based on batch size: (1) Stochastic gradient descent (2) Batch gradient descent (3) Mini Batch gradient descent\\n\\nIf the whole data is in a single batch, it is called batch gradient descent. If the single data points are equal to one batch i.e. number of batches = number of data instances, it is called stochastic gradient descent. If the number of batches is less than the number of data points or greater than 1, it is known as mini-batch gradient descent.\\n\\n### Q29: What are the different methods to split a tree in a decision tree algorithm? ###\\n\\nAnswer:\\n\\nDecision trees can be of two types regression and classification.\\nFor classification, classification accuracy created a lot of instability. So the following loss functions are used:\\n- Gini\\'s Index\\nGini impurity is used to predict the likelihood of a randomly chosen example being incorrectly classified by a particular node. It’s referred to as an “impurity” measure because it demonstrates how the model departs from a simple division.\\n\\n- Cross-entropy or Information Gain\\nInformation gain refers to the process of identifying the most important features/attributes that convey the most information about a class. The entropy principle is followed with the goal of reducing entropy from the root node to the leaf nodes. Information gain is the difference in entropy before and after splitting, which describes the impurity of in-class items.\\n\\n\\nFor regression, the good old mean squared error serves as a good loss function which is minimized by splits of the input features and predicting the mean value of the target feature on the subspaces resulting from the split. But finding the split that results in the minimum possible residual sum of squares is computationally infeasible, so a greedy top-down approach is taken i.e. the splits are made at a level from top to down which results in maximum reduction of RSS. We continue this until some maximum depth or number of leaves is attained.\\n\\n### Q30: Why boosting is a more stable algorithm as compared to other ensemble algorithms? ###\\n\\nAnswer:\\n\\nBoosting algorithms focus on errors found in previous iterations until they become obsolete. Whereas in bagging there is no corrective loop. That’s why boosting is a more stable algorithm compared to other ensemble algorithms.\\n\\n### Q31: What is active learning and discuss one strategy of it? ###\\n\\nAnswer:\\nActive learning is a special case of machine learning in which a learning algorithm can interactively query a user (or some other information source) to label new data points with the desired outputs. In statistics literature, it is sometimes referred to as optimal experimental design.\\n\\n1. Stream-based sampling \\nIn stream-based selective sampling, unlabelled data is continuously fed to an active learning system, where the learner decides whether to send the same to a human oracle or not based on a predefined learning strategy. This method is apt in scenarios where the model is in production and the data sources/distributions vary over time. \\n\\n2. Pool-based sampling\\nIn this case, the data samples are chosen from a pool of unlabelled data based on the informative value scores and sent for manual labeling. Unlike stream-based sampling, oftentimes, the entire unlabelled dataset is scrutinized for the selection of the best instances.\\n\\n![1669836673164](https://user-images.githubusercontent.com/72076328/204896144-43b2181a-d9ce-471b-95d0-44c0f7bb3025.jpg)\\n\\n### Q32: What are the different approaches to implementing recommendation systems? ###\\nAnswer:\\n1. 𝐂𝐨𝐧𝐭𝐞𝐧𝐭-𝐁𝐚𝐬𝐞𝐝 𝐅𝐢𝐥𝐭𝐞𝐫𝐢𝐧𝐠: Content-Based Filtering depends on similarities of items and users\\' past activities on the website to recommend any product or service.\\n\\nThis filter helps in avoiding a cold start for any new products as it doesn\\'t rely on other users\\' feedback, it can recommend products based on similarity factors. However, content-based filtering needs a lot of domain knowledge so that the recommendations made are 100 percent accurate.\\n\\n2. 𝐂𝐨𝐥𝐥𝐚𝐛𝐨𝐫𝐚𝐭𝐢𝐯𝐞-𝐁𝐚𝐬𝐞𝐝 𝐅𝐢𝐥𝐭𝐞𝐫𝐢𝐧𝐠: The primary job of a collaborative filtering system is to overcome the shortcomings of content-based filtering.\\n\\nSo, instead of focusing on just one user, the collaborative filtering system focuses on all the users and clusters them according to their interests.\\n\\nBasically, it recommends a product \\'x\\' to user \\'a\\' based on the interest of user \\'b\\'; users \\'a\\' and \\'b\\' must have had similar interests in the past, which is why they are clustered together.\\n\\nThe domain knowledge that is required for collaborative filtering is less, recommendations made are more accurate and it can adapt to the changing tastes of users over time. However, collaborative filtering faces the problem of a cold start as it heavily relies on feedback or activity from other users.\\n\\n3. 𝐇𝐲𝐛𝐫𝐢𝐝 𝐟𝐢𝐥𝐭𝐞𝐫𝐢𝐧𝐠:  A mixture of content and collaborative methods. Uses descriptors and interactions.\\n\\nMore modern approaches typically fall into the hybrid filtering category and tend to work in two stages:\\n\\n1). A candidate generation phase where we coarsely generate candidates from a corpus of hundreds of thousands, millions, or billions of items down to a few hundred or thousand\\n\\n2) A ranking phase where we re-rank the candidates into a final top-n set to be shown to the user. Some systems employ multiple candidate generation methods and rankers.\\n\\n### Q33: What are the evaluation metrics that can be used for multi-label classification? ###\\n\\nAnswer:\\n\\nMulti-label classification is a type of classification problem where each instance can be assigned to multiple classes or labels simultaneously.\\n\\nThe evaluation metrics for multi-label classification are designed to measure the performance of a multi-label classifier in predicting the correct set of labels for each instance.\\nSome commonly used evaluation metrics for multi-label classification are:\\n\\n1. Hamming Loss: Hamming Loss is the fraction of labels that are incorrectly predicted. It is defined as the average number of labels that are predicted incorrectly per instance.\\n\\n2. Accuracy: Accuracy is the fraction of instances that are correctly predicted. In multi-label classification, accuracy is calculated as the percentage of instances for which all labels are predicted correctly.\\n\\n3. Precision, Recall, F1-Score: These metrics can be applied to each label separately, treating the classification of each label as a separate binary classification problem. Precision measures the proportion of predicted positive labels that are correct, recall measures the proportion of actual positive labels that are correctly predicted, and F1-score is the harmonic mean of precision and recall.\\n\\n4. Macro-F1, Micro-F1: Macro-F1 and Micro-F1 are two types of F1-score metrics that take into account the label imbalance in the dataset. Macro-F1 calculates the F1-score for each label and then averages them, while Micro-F1 calculates the overall F1-score by aggregating the true positive, false positive, and false negative counts across all labels.\\n\\nThere are other metrics that can be used such as:\\n* Precision at k (P@k)\\n* Average precision at k (AP@k)\\n* Mean average precision at k (MAP@k)\\n\\n\\n### Q34: What is the difference between concept and data drift and how to overcome each of them? ###\\n\\nAnswer:\\n\\nConcept drift and data drift are two different types of problems that can occur in machine learning systems.\\n\\nConcept drift refers to changes in the underlying relationships between the input data and the target variable over time. This means that the distribution of the data that the model was trained on no longer matches the distribution of the data it is being tested on. For example, a spam filter model that was trained on emails from several years ago may not be as effective at identifying spam emails from today because the language and tactics used in spam emails may have changed.\\n\\nData drift, on the other hand, refers to changes in the input data itself over time. This means that the values of the input feature that the model was trained on no longer match the values of the input features in the data it is being tested on. For example, a model that was trained on data from a particular geographical region may not be as effective at predicting outcomes for data from a different region.\\n\\nTo overcome concept drift, one approach is to use online learning methods that allow the model to adapt to new data as it arrives. This involves continually training the model on the most recent data while using historical data to maintain context. Another approach is to periodically retrain the model using a representative sample of the most recent data.\\n\\nTo overcome data drift, one approach is to monitor the input data for changes and retrain the model when significant changes are detected. This may involve setting up a monitoring system that alerts the user when the data distribution changes beyond a certain threshold.\\n\\nAnother approach is to preprocess the input data to remove or mitigate the effects of the features changing over time so that the model can continue learning from the remaining features.\\n![ezgif com-webp-to-jpg (7)](https://user-images.githubusercontent.com/72076328/221916192-7a9fcf21-8e5f-4ddc-bd90-ef1bdabf1d3f.jpg)\\n\\n### Q35: Can you explain the ARIMA model and its components? ###\\nAnswer:\\nThe ARIMA model, which stands for Autoregressive Integrated Moving Average, is a widely used time series forecasting model. It combines three key components: Autoregression (AR), Differencing (I), and Moving Average (MA).\\n\\n* Autoregression (AR):\\nThe autoregressive component captures the relationship between an observation in a time series and a certain number of lagged observations. It assumes that the value at a given time depends linearly on its own previous values. The \"p\" parameter in ARIMA(p, d, q) represents the order of autoregressive terms. For example, ARIMA(1, 0, 0) refers to a model with one autoregressive term.\\n\\n* Differencing (I):\\nDifferencing is used to make a time series stationary by removing trends or seasonality. It calculates the difference between consecutive observations to eliminate any non-stationary behavior. The \"d\" parameter in ARIMA(p, d, q) represents the order of differencing. For instance, ARIMA(0, 1, 0) indicates that differencing is applied once.\\n\\n* Moving Average (MA):\\nThe moving average component takes into account the dependency between an observation and a residual error from a moving average model applied to lagged observations. It assumes that the value at a given time depends linearly on the error terms from previous time steps. The \"q\" parameter in ARIMA(p, d, q) represents the order of the moving average terms. For example, ARIMA(0, 0, 1) signifies a model with one moving average term.\\n\\nBy combining these three components, the ARIMA model can capture both autoregressive patterns, temporal dependencies, and stationary behavior in a time series. The parameters p, d, and q are typically determined through techniques like the Akaike Information Criterion (AIC) or Bayesian Information Criterion (BIC).\\n\\nIt\\'s worth noting that there are variations of the ARIMA model, such as SARIMA (Seasonal ARIMA), which incorporates additional seasonal components for modeling seasonal patterns in the data.\\n\\nARIMA models are widely used in forecasting applications, but they do make certain assumptions about the underlying data, such as linearity and stationarity. It\\'s important to validate these assumptions and adjust the model accordingly if they are not met.\\n![1-1](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/assets/72076328/12707951-bdf5-4cd1-9efd-c60c465007a3)\\n\\n### Q36: What are the assumptions made by the ARIMA model? ###\\nAnswer:\\n\\nThe ARIMA model makes several assumptions about the underlying time series data. These assumptions are important to ensure the validity and accuracy of the model\\'s results. Here are the key assumptions:\\n\\nStationarity: The ARIMA model assumes that the time series is stationary. Stationarity means that the statistical properties of the data, such as the mean and variance, remain constant over time. This assumption is crucial for the autoregressive and moving average components to hold. If the time series is non-stationary, differencing (the \"I\" component) is applied to transform it into a stationary series.\\n\\nLinearity: The ARIMA model assumes that the relationship between the observations and the lagged values is linear. It assumes that the future values of the time series can be modeled as a linear combination of past values and error terms.\\n\\nNo Autocorrelation in Residuals: The ARIMA model assumes that the residuals (the differences between the predicted values and the actual values) do not exhibit any autocorrelation. In other words, the errors are not correlated with each other.\\n\\nNormally Distributed Residuals: The ARIMA model assumes that the residuals follow a normal distribution with a mean of zero. This assumption is necessary for statistical inference, parameter estimation, and hypothesis testing.\\n\\nIt\\'s important to note that while these assumptions are commonly made in ARIMA modeling, they may not always hold in real-world scenarios. It\\'s essential to assess the data and, if needed, apply transformations or consider alternative models that relax some of these assumptions. Additionally, diagnostics tools, such as residual analysis and statistical tests, can help evaluate the adequacy of the assumptions and the model\\'s fit to the data.\\n')]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLyVTymIxYku"
      },
      "source": [
        "## Wrap text while preserving newlines using the `textwrap` module in Python.\n",
        "\n",
        "\n",
        "*  **Preserve Line Breaks:** The function ensures that existing line breaks in the text are maintained while formatting each line to a specified width, which is useful for readability and consistent formatting.\n",
        "\n",
        "* **Control Line Length:** By wrapping lines to a maximum width, the function helps in managing text presentation, making it suitable for outputs like console logs, text files, or documents where line length consistency is important.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qwI5wcPO6ySf"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "\n",
        "def wrap_text_preserve_newlines(text, width=110):\n",
        "    # Split the input text into lines based on newline characters\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    # Wrap each line individually\n",
        "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
        "\n",
        "    # Join the wrapped lines back together using newline characters\n",
        "    wrapped_text = '\\n'.join(wrapped_lines)\n",
        "\n",
        "    return wrapped_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOuvOh_i66Hz",
        "outputId": "6a837ca2-ec52-4a0e-8804-cacb128cf8ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='# Machine Learning Interview Questions & Answers for Data Scientists #\n",
            "\n",
            "## Questions ##\n",
            "* [Q1: Mention three ways to make your model robust to outliers?](https://github.com/youssefHosni/Data-\n",
            "Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for\n",
            "%20Data%20Scientists.md#q1-mention-three-ways-to-make-your-model-robust-to-outliers)\n",
            "* [Q2: Describe the motivation behind random forests and mention two reasons why they are better than\n",
            "individual decision trees?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main\n",
            "/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q2-describe-the-\n",
            "motivation-behind-random-forests-and-mention-two-reasons-why-they-are-better-than-individual-decision-trees)\n",
            "* [Q3: What are the differences and similarities between gradient boosting and random forest? and what are the\n",
            "advantages and disadvantages of each when compared to each other?](https://github.com/youssefHosni/Data-\n",
            "Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for\n",
            "%20Data%20Scientists.md#q3-what-are-the-differences-and-similarities-between-gradient-boosting-and-random-\n",
            "forest-and-what-are-the-advantage-and-disadvantages-of-each-when-compared-to-each-other)\n",
            "* [Q4: What are L1 and L2 regularization? What are the differences between the\n",
            "two?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20\n",
            "Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q4-what-are-l1-and-l2-regularization-what-\n",
            "are-the-differences-between-the-two)\n",
            "* [Q5: What are the Bias and Variance in a Machine Learning Model and explain the bias-variance trade-\n",
            "off?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20\n",
            "Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q5-what-are-the-bias-and-variance-in-a-\n",
            "machine-learning-model-and-explain-the-bias-variance-trade-off)\n",
            "* [Q6: Mention three ways to handle missing or corrupted data in a\n",
            "dataset?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learnin\n",
            "g%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q6-mention-three-ways-to-handle-\n",
            "missing-or-corrupted-data-in-a-dataset)\n",
            "* [Q7: Explain briefly the logistic regression model and state an example of when you have used it\n",
            "recently?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learni\n",
            "ng%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q7-explain-briefly-the-logistic-\n",
            "regression-model-and-state-an-example-of-when-you-have-used-it-recently)\n",
            "* [Q8: Explain briefly batch gradient descent, stochastic gradient descent, and mini-batch gradient descent.\n",
            "and what are the pros and cons for each of them?](https://github.com/youssefHosni/Data-Science-Interview-\n",
            "Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientis\n",
            "ts.md#q8-explain-briefly-batch-gradient-descent-stochastic-gradient-descent-and-mini-batch-gradient-descent-\n",
            "and-what-are-the-pros-and-cons-for-each-of-them)\n",
            "* [Q9: Explain what is information gain and entropy in the context of decision\n",
            "trees?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%\n",
            "20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q9-explain-what-is-information-gain-and-\n",
            "entropy-in-the-context-of-decision-trees)\n",
            "* [Q10: Explain the linear regression model and discuss its assumption?](https://github.com/youssefHosni/Data-\n",
            "Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for\n",
            "%20Data%20Scientists.md#q10-explain-the-linear-regression-model-and-discuss-its-assumption)\n",
            "* [Q11: Explain briefly the K-Means clustering and how can we find the best value of\n",
            "K?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20In\n",
            "terview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q11-explain-briefly-the-k-means-clustering-\n",
            "and-how-can-we-find-the-best-value-of-k)\n",
            "* [Q12: Define Precision, recall, and F1 and discuss the trade-off between\n",
            "them?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%2\n",
            "0Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q12-define-precision-recall-and-f1-and-\n",
            "discuss-the-trade-off-between-them)\n",
            "* [Q13: What are the differences between a model that minimizes squared error and the one that minimizes the\n",
            "absolute error? and in which cases each error metric would be more\n",
            "appropriate?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Lea\n",
            "rning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q13-what-are-the-differences-\n",
            "between-a-model-that-minimizes-squared-error-and-the-one-that-minimizes-the-absolute-error-and-in-which-cases-\n",
            "each-error-metric-would-be-more-appropriate)\n",
            "* [Q14: Define and compare parametric and non-parametric models and give two examples for each of\n",
            "them?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%2\n",
            "0Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q14-define-and-compare-parametric-and-non-\n",
            "parametric-models-and-give-two-examples-for-each-of-them)\n",
            "* [Q15: Explain the kernel trick in SVM and why we use it and how to choose what kernel to\n",
            "use?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20\n",
            "Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q15-explain-the-kernel-trick-in-svm-and-\n",
            "why-we-use-it-and-how-to-choose-what-kernel-to-use)\n",
            "* [Q16: Define the cross-validation process and the motivation behind using\n",
            "it?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20I\n",
            "nterview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q16-define-the-cross-validation-process-and-\n",
            "the-motivation-behind-using-it)\n",
            "* [Q17: You are building a binary classifier and you found that the data is imbalanced, what should you do to\n",
            "handle this situation?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Mac\n",
            "hine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q17-you-are-building-a-\n",
            "binary-classifier-and-you-found-that-the-data-is-imbalanced-what-should-you-do-to-handle-this-situation)\n",
            "* [Q18: You are working on a clustering problem, what are different evaluation metrics that can be used, and\n",
            "how to choose between them?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/mai\n",
            "n/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q18-you-are-working-\n",
            "on-a-clustering-problem-what-are-different-evaluation-metrics-that-can-be-used-and-how-to-choose-between-them)\n",
            "* [Q19: What is the ROC curve and when should you use it?](https://github.com/youssefHosni/Data-Science-\n",
            "Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%\n",
            "20Scientists.md#q19-what-is-the-roc-curve-and-when-should-you-use-it)\n",
            "* [Q20: What is the difference between hard and soft voting classifiers in the context of ensemble\n",
            "learners?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learni\n",
            "ng%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q20-what-is-the-difference-between-\n",
            "hard-and-soft-voting-classifiers-in-the-context-of-ensemble-learners)\n",
            "* [Q21: What is boosting in the context of ensemble learners discuss two famous boosting\n",
            "methods](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning\n",
            "%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q21-what-is-boosting-in-the-context-of-\n",
            "ensemble-learners-discuss-two-famous-boosting-methods)\n",
            "* [Q22: How can you evaluate the performance of a dimensionality reduction algorithm on your\n",
            "dataset?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learnin\n",
            "g%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q22-how-can-you-evaluate-the-\n",
            "performance-of-a-dimensionality-reduction-algorithm-on-your-dataset)\n",
            "* [Q23: Define the curse of dimensionality and how to solve it. ](https://github.com/youssefHosni/Data-\n",
            "Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for\n",
            "%20Data%20Scientists.md#q23-define-the-curse-of-dimensionality-and-how-to-solve-it)\n",
            "* [Q24: In what cases would you use vanilla PCA, Incremental PCA, Randomized PCA, or Kernel\n",
            "PCA?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20\n",
            "Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q24-in-what-cases-would-you-use-vanilla-\n",
            "pca-incremental-pca-randomized-pca-or-kernel-pca)\n",
            "* [Q25: Discuss two clustering algorithms that can scale to large\n",
            "datasets](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learnin\n",
            "g%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q25-discuss-two-clustering-algorithms-\n",
            "that-can-scale-to-large-datasets)\n",
            "* [Q26: Do you need to scale your data if you will be using the SVM classifier and discuss your\n",
            "answer](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%\n",
            "20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q26-do-you-need-to-scale-your-data-if-\n",
            "you-will-be-using-the-svm-classifier-and-discus-your-answer)\n",
            "* [Q27: What are Loss Functions and Cost Functions? Explain the key Difference Between\n",
            "them.](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%2\n",
            "0Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q27-what-are-loss-functions-and-cost-\n",
            "functions-explain-the-key-difference-between-them)\n",
            "* [Q28: What is the importance of batch in machine learning and explain some batch depend on gradient descent\n",
            "algorithm?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learn\n",
            "ing%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q28-what-is-the-importance-of-batch-\n",
            "in-machine-learning-and-explain-some-batch-depend-gradient-descent-algorithm)\n",
            "* [Q29: What are the different methods to split a tree in a decision tree\n",
            "algorithm?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learn\n",
            "ing%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q29-what-are-the-different-methods-\n",
            "to-split-a-tree-in-a-decision-tree-algorithm)\n",
            "* [Q30: Why boosting is a more stable algorithm as compared to other ensemble algorithms?\n",
            "](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Inte\n",
            "rview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q30-why-boosting-is-a-more-stable-algorithm-as-\n",
            "compared-to-other-ensemble-algorithms)\n",
            "* [Q31: What is active learning and discuss one strategy of it?](https://github.com/youssefHosni/Data-Science-\n",
            "Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%\n",
            "20Scientists.md#q31-what-is-active-learning-and-discuss-one-strategy-of-it)\n",
            "* [Q32: What are the different approaches to implementing recommendation\n",
            "systems?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learnin\n",
            "g%20Interview%20Questions%20&%20Answers%20for%20Data%20Scientists.md#:~:text=the%20best%20instances.-\n",
            ",Q32%3A%20What%20are%20the%20different%20approaches%20to%20implementing%20recommendation%20systems%3F,-\n",
            "Answer%3A)\n",
            "* [Q33: What are the evaluation metrics that can be used for multi-label\n",
            "classification?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20\n",
            "Learning%20Interview%20Questions%20&%20Answers%20for%20Data%20Scientists.md#:~:text=Q33%3A%20What%20are%20the%\n",
            "20evaluation%20metrics%20that%20can%20be%20used%20for%20multi%2Dlabel%20classification%3F)\n",
            "* [Q34: What is the difference between concept and data drift and how to overcome each of\n",
            "them?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%2\n",
            "0Interview%20Questions%20&%20Answers%20for%20Data%20Scientists.md#:~:text=at%20k%20(MAP%40k)-\n",
            ",Q34%3A%20What%20is%20the%20difference%20between%20concept%20and%20data%20drift%20and%20how%20to%20overcome%20\n",
            "each%20of%20them%3F,-Answer%3A)\n",
            "* [Q35: Can you explain the ARIMA model and its components?]()\n",
            "* [Q36: What are the assumptions made by the ARIMA model?]()\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "-----------------------------------------------\n",
            "\n",
            "## Questions & Answers ##\n",
            "\n",
            "### Q1: Mention three ways to make your model robust to outliers. ###\n",
            "\n",
            "Investigating the outliers is always the first step in understanding how to treat them. After you understand\n",
            "the nature of why the outliers occurred you can apply one of the several methods mentioned\n",
            "[here](https://365datascience.com/career-advice/job-interview-tips/machine-learning-interview-questions-and-an\n",
            "swers/#11:~:text=for%20large%20datasets.-\n",
            ",Bonus%20Question%3A%20Discuss%20how%20to%20make%20your%20model%20robust%20to%20outliers.,-\n",
            "There%20are%20several).\n",
            "\n",
            "### Q2: Describe the motivation behind random forests and mention two reasons why they are better than\n",
            "individual decision trees. ###\n",
            "\n",
            "The motivation behind random forest or ensemble models in general in layman's terms, Let's say we have a\n",
            "question/problem to solve we bring 100 people and ask each of them the question/problem and record their\n",
            "solution. The rest of the answer is [here](https://365datascience.com/career-advice/job-interview-\n",
            "tips/machine-learning-interview-questions-and-answers/#2:~:text=2.%20Describe%20the%20motivation%20behind%20ra\n",
            "ndom%20forests%20and%20mention%20two%20reasons%20why%20they%20are%20better%20than%20individual%20decision%C2%A\n",
            "0trees.)\n",
            "\n",
            "### Q3: What are the differences and similarities between gradient boosting and random forest? and what are\n",
            "the advantages and disadvantages of each when compared to each other? ###\n",
            "\n",
            "Similarities:\n",
            "1. Both these algorithms are decision-tree-based algorithms\n",
            "2. Both these algorithms are ensemble algorithms\n",
            "3. Both are flexible models and do not need much data preprocessing.\n",
            "\n",
            "The rest of the answer is [here](https://365datascience.com/career-advice/job-interview-tips/machine-learning-\n",
            "interview-questions-and-answers/#2:~:text=3.%20What%20are%20the%20differences%20and%20similarities%20between%2\n",
            "0gradient%20boosting%20and%20random%20forest%3F%20And%20what%20are%20the%20advantages%20and%20disadvantages%20\n",
            "of%20each%20when%20compared%20to%20each%C2%A0other%3F)\n",
            "\n",
            "### Q4: What are L1 and L2 regularization? What are the differences between the two? ###\n",
            "\n",
            "Answer:\n",
            "\n",
            "Regularization is a technique used to avoid overfitting by trying to make the model more simple.The rest of\n",
            "the answer is [here](https://365datascience.com/career-advice/job-interview-tips/machine-learning-interview-\n",
            "questions-and-answers/#2:~:text=6.%20What%20are%20L1%20and%20L2%20regularizations%3F%20What%20are%20the%20diff\n",
            "erences%20between%20the%C2%A0two%3F)\n",
            "### Q5: What are the Bias and Variance in a Machine Learning Model and explain the bias-variance trade-off?\n",
            "###\n",
            "\n",
            "Answer:\n",
            "\n",
            "The goal of any supervised machine learning model is to estimate the mapping function (f) that predicts the\n",
            "target variable (y) given input (x). The prediction error can be broken down into three parts:\n",
            "The rest of the answer is [here](https://365datascience.com/career-advice/job-interview-tips/machine-learning-\n",
            "interview-questions-and-answers/#2:~:text=8.%20What%20are%20the%20bias%20and%20variance%20in%20a%20machine%20l\n",
            "earning%20model%20and%20explain%20the%20bias%2Dvariance%20trade%2Doff%3F)\n",
            "\n",
            "### Q6: Mention three ways to handle missing or corrupted data in a dataset. ###\n",
            "\n",
            "Answer:\n",
            "\n",
            "In general, real-world data often has a lot of missing values. The cause of missing values can be data\n",
            "corruption or failure to record data. The rest of the answer is [here](https://365datascience.com/career-\n",
            "advice/job-interview-tips/machine-learning-interview-questions-and-answers/#9:~:text=10.-\n",
            ",Mention%20three%20ways%20to%20handle%20missing%20or%20corrupted%20data%20in%20a%C2%A0dataset.,-\n",
            "In%20general%2C%20real)\n",
            "\n",
            "### Q7: Explain briefly the logistic regression model and state an example of when you have used it recently.\n",
            "###\n",
            "\n",
            "Answer:\n",
            "\n",
            "Logistic regression is used to calculate the probability of occurrence of an event in the form of a dependent\n",
            "output variable based on independent input variables. Logistic regression is commonly used to estimate the\n",
            "probability that an instance belongs to a particular class. If the probability is bigger than 0.5 then it will\n",
            "belong to that class (positive) and if it is below 0.5 it will belong to the other class. This will make it a\n",
            "binary classifier.\n",
            "\n",
            "It is important to remember that the Logistic regression isn't a classification model, it's an ordinary type\n",
            "of regression algorithm, and it was developed and used before machine learning, but it can be used in\n",
            "classification when we put a threshold to determine specific categories\"\n",
            "\n",
            "There is a lot of classification applications to it:\n",
            "\n",
            "Classify email as spam or not, To identify whether the patient is healthy or not, and so on.\n",
            "\n",
            "### Q8: Explain briefly batch gradient descent, stochastic gradient descent, and mini-batch gradient descent.\n",
            "and what are the pros and cons for each of them? ###\n",
            "\n",
            "Gradient descent is a generic optimization algorithm cable for finding optimal solutions to a wide range of\n",
            "problems. The general idea of gradient descent is to tweak parameters iteratively in order to minimize a cost\n",
            "function.\n",
            "\n",
            "Batch Gradient Descent:\n",
            "In Batch Gradient descent the whole training data is used to minimize the loss function by taking a step\n",
            "toward the nearest minimum by calculating the gradient (the direction of descent)\n",
            "\n",
            "Pros:\n",
            "Since the whole data set is used to calculate the gradient it will be stable and reach the minimum of the cost\n",
            "function without bouncing (if the learning rate is chosen cooreclty)\n",
            "\n",
            "Cons:\n",
            "\n",
            "Since batch gradient descent uses all the training set to compute the gradient at every step, it will be very\n",
            "slow especially if the size of the training data is large.\n",
            "\n",
            "\n",
            "Stochastic Gradient Descent:\n",
            "\n",
            "Stochastic Gradient Descent picks up a random instance in the training data set at every step and computes the\n",
            "gradient based only on that single instance.\n",
            "\n",
            "Pros:\n",
            "1. It makes the training much faster as it only works on one instance at a time.\n",
            "2. It become easier to train large datasets\n",
            "\n",
            "Cons:\n",
            "\n",
            "Due to the stochastic (random) nature of this algorithm, this algorithm is much less regular than the batch\n",
            "gradient descent. Instead of gently decreasing until it reaches the minimum, the cost function will bounce up\n",
            "and down, decreasing only on average. Over time it will end up very close to the minimum, but once it gets\n",
            "there it will continue to bounce around, not settling down there. So once the algorithm stops the final\n",
            "parameters are good but not optimal. For this reason, it is important to use a training schedule to overcome\n",
            "this randomness.\n",
            "\n",
            "Mini-batch Gradient:\n",
            "\n",
            "At each step instead of computing the gradients on the whole data set as in the Batch Gradient Descent or\n",
            "using one random instance as in the Stochastic Gradient Descent, this algorithm computes the gradients on\n",
            "small random sets of instances called mini-batches.\n",
            "\n",
            "Pros:\n",
            "1. The algorithm's progress space is less erratic than with Stochastic Gradient Descent, especially with large\n",
            "mini-batches.\n",
            "2. You can get a performance boost from hardware optimization of matrix operations, especially when using\n",
            "GPUs.\n",
            "\n",
            "Cons:\n",
            "1. It might be difficult to escape from local minima.\n",
            "\n",
            "![alt text](https://github.com/youssefHosni/Data-Science-Interview-\n",
            "Questions/blob/main/Figures/gradient%20descent%20vs%20batch%20gradient%20descent.png)\n",
            "\n",
            "### Q9: Explain what is information gain and entropy in the context of decision trees. ###\n",
            "Entropy and Information Gain are two key metrics used in determining the relevance of decision-making when\n",
            "constructing a decision tree model and determining the nodes and the best way to split.\n",
            "\n",
            "The idea of a decision tree is to divide the data set into smaller data sets based on the descriptive features\n",
            "until we reach a small enough set that contains data points that fall under one label.\n",
            "\n",
            "Entropy is the measure of impurity, disorder, or uncertainty in a bunch of examples. Entropy controls how a\n",
            "Decision Tree decides to split the data.\n",
            "Information gain calculates the reduction in entropy or surprise from transforming a dataset in some way. It\n",
            "is commonly used in the construction of decision trees from a training dataset, by evaluating the information\n",
            "gain for each variable and selecting the variable that maximizes the information gain, which in turn minimizes\n",
            "the entropy and best splits the dataset into groups for effective classification.\n",
            "\n",
            "### Q10: Explain the linear regression model and discuss its assumption. ###\n",
            "Linear regression is a supervised statistical model to predict dependent variable quantity based on\n",
            "independent variables.\n",
            "Linear regression is a parametric model and the objective of linear regression is that it has to learn\n",
            "coefficients using the training data and predict the target value given only independent values.\n",
            "\n",
            "Some of the linear regression assumptions and how to validate them:\n",
            "\n",
            "1. Linear relationship between independent and dependent variables\n",
            "2. Independent residuals and the constant residuals at every x\n",
            "We can check for 1 and 2 by plotting the residuals(error terms) against the fitted values (upper left graph).\n",
            "Generally, we should look for a lack of patterns and a consistent variance across the horizontal line.\n",
            "3. Normally distributed residuals\n",
            "We can check for this using a couple of methods:\n",
            "* Q-Q-plot(upper right graph): If data is normally distributed, points should roughly align with the 45-degree\n",
            "line.\n",
            "* Boxplot: it also helps visualize outliers\n",
            "* Shapiro–Wilk test: If the p-value is lower than the chosen threshold, then the null hypothesis (Data is\n",
            "normally distributed) is rejected.\n",
            "4. Low multicollinearity\n",
            "* you can calculate the VIF (Variable Inflation Factors) using your favorite statistical tool. If the value\n",
            "for each covariate is lower than 10 (some say 5), you're good to go.\n",
            "\n",
            "The figure below summarizes these assumptions.\n",
            "![alt text](https://github.com/youssefHosni/Data-Science-Interview-\n",
            "Questions/blob/main/Figures/Linear%20regression%20assumptions.jpg)\n",
            "\n",
            "### Q11: Explain briefly the K-Means clustering and how can we find the best value of K? ###\n",
            "K-Means is a well-known clustering algorithm. K-means clustering is often used because it is easy to interpret\n",
            "and implement. The rest of the answer is [here](https://365datascience.com/career-advice/job-interview-\n",
            "tips/machine-learning-interview-questions-and-answers/#2:~:text=4.%20Briefly%20explain%20the%20K%2DMeans%20clu\n",
            "stering%20and%20how%20can%20we%20find%20the%20best%20value%20of%C2%A0K.)\n",
            "\n",
            "### Q12: Define Precision, recall, and F1 and discuss the trade-off between them? ###\n",
            "\n",
            "Precision and recall are two classification evaluation metrics that are used beyond accuracy. The rest of the\n",
            "answer is [here](https://365datascience.com/career-advice/job-interview-tips/machine-learning-interview-\n",
            "questions-and-answers/#9:~:text=9.-\n",
            ",Define%20precision%2C%20recall%2C%20and%20F1%20and%20discuss%20the%20trade%2Doff%20between%C2%A0them.,-\n",
            "Precision%20and%20recall)\n",
            "\n",
            "### Q13: What are the differences between a model that minimizes squared error and the one that minimizes the\n",
            "absolute error? and in which cases each error metric would be more appropriate? ###\n",
            "\n",
            "Both mean square error (MSE) and mean absolute error (MAE) measures the distances between vectors and express\n",
            "average model prediction in units of the target variable. Both can range from 0 to infinity, the lower they\n",
            "are the better the model.\n",
            "\n",
            "The main difference between them is that in MSE the errors are squared before being averaged while in MAE they\n",
            "are not. This means that a large weight will be given to large errors. MSE is useful when large errors in the\n",
            "model are trying to be avoided. This means that outliers affect MSE more than MAE, that is why MAE is more\n",
            "robust to outliers.\n",
            "Computation-wise MSE is easier to use as the gradient calculation will be more straightforward than MAE, which\n",
            "requires linear programming to calculate it.\n",
            "\n",
            "### Q14: Define and compare parametric and non-parametric models and give two examples for each of them? ###\n",
            "\n",
            "Answer:\n",
            "\n",
            "**Parametric models** assume that the dataset comes from a certain function with some set of parameters that\n",
            "should be tuned to reach the optimal performance. For such models, the number of parameters is determined\n",
            "prior to training, thus the degree of freedom is limited and reduces the chances of overfitting.\n",
            "\n",
            "Ex. Linear Regression, Logistic Regression, LDA\n",
            "\n",
            "**Nonparametric models** don't assume anything about the function from which the dataset was sampled. For\n",
            "these models, the number of parameters is not determined prior to training, thus they are free to generalize\n",
            "the model based on the data. Sometimes these models overfit themselves while generalizing. To generalize they\n",
            "need more data in comparison with Parametric Models. They are relatively more difficult to interpret compared\n",
            "to Parametric Models.\n",
            "\n",
            "Ex. Decision Tree, Random Forest.\n",
            "\n",
            "### Q15: Explain the kernel trick in SVM. Why do we use it and how to choose what kernel to use? ###\n",
            "Answer:\n",
            "Kernels are used in SVM to map the original input data into a particular higher dimensional space where it\n",
            "will be easier to find patterns in the data and train the model with better performance.\n",
            "\n",
            "For eg.: If we have binary class data which form a ring-like pattern (inner and outer rings representing two\n",
            "different class instances) when plotted in 2D space, a linear SVM kernel will not be able to differentiate the\n",
            "two classes well when compared to an RBF (radial basis function) kernel, mapping the data into a particular\n",
            "higher dimensional space where the two classes are clearly separable.\n",
            "\n",
            "Typically without the kernel trick, in order to calculate support vectors and support vector classifiers, we\n",
            "need first to transform data points one by one to the higher dimensional space, do the calculations based on\n",
            "SVM equations in the higher dimensional space, and then return the results. The ‘trick’ in the kernel trick is\n",
            "that we design the kernels based on some conditions as mathematical functions that are equivalent to a dot\n",
            "product in the higher dimensional space without even having to transform data points to the higher dimensional\n",
            "space. i.e. we can calculate support vectors and support vector classifiers in the same space where the data\n",
            "is provided which saves a lot of time and calculations.\n",
            "\n",
            "Having domain knowledge can be very helpful in choosing the optimal kernel for your problem, however, in the\n",
            "absence of such knowledge following this default rule can be helpful:\n",
            "For linear problems, we can try linear or logistic kernels, and for nonlinear problems, we can use RBF or\n",
            "Gaussian kernels.\n",
            "\n",
            "![Alt_text](https://github.com/youssefHosni/Data-Science-Interview-\n",
            "Questions/blob/main/Figures/Kerenl%20trick.png)\n",
            "\n",
            "### Q16: Define the cross-validation process and the motivation behind using it. ###\n",
            "Cross-validation is a technique used to assess the performance of a learning model in several subsamples of\n",
            "training data. In general, we split the data into train and test sets where we use the training data to train\n",
            "our model and the test data to evaluate the performance of the model on unseen data and validation set for\n",
            "choosing the best hyperparameters. Now, a random split in most cases(for large datasets) is fine. However, for\n",
            "smaller datasets, it is susceptible to loss of important information present in the data in which it was not\n",
            "trained. Hence, cross-validation though computationally expensive combats this issue.\n",
            "\n",
            "The process of cross-validation is as follows:\n",
            "\n",
            "1. Define k or the number of folds\n",
            "2. Randomly shuffle the data into K equally-sized blocks (folds)\n",
            "3. For each i in fold 1 to k train the data using all the folds except for fold i and test on the fold i.\n",
            "3. Average the K validation/test error from the previous step to get an estimate of the error.\n",
            "\n",
            "This process aims to accomplish the following:\n",
            "1- Prevent overfitting during training by avoiding training and testing on the same subset of the data points\n",
            "\n",
            "2- Avoid information loss by using a certain subset of the data for validation only. This is important for\n",
            "small datasets.\n",
            "\n",
            "Cross-validation is always good to be used for small datasets, and if used for large datasets the\n",
            "computational complexity will increase depending on the number of folds.\n",
            "\n",
            "![Alt_text](https://github.com/youssefHosni/Data-Science-Interview-\n",
            "Questions/blob/main/Figures/cross%20validation.png)\n",
            "\n",
            "### Q17: You are building a binary classifier and you found that the data is imbalanced, what should you do to\n",
            "handle this situation? ###\n",
            "Answer:\n",
            "If there is a data imbalance there are several measures we can take to train a fairer binary classifier:\n",
            "\n",
            "**1. Pre-Processing:**\n",
            "\n",
            "* Check whether you can get more data or not.\n",
            "\n",
            "* Use sampling techniques (Sample minority class, Downsample majority class, can take the hybrid approach as\n",
            "well). We can also use data augmentation to add more data points for the minority class but with little\n",
            "deviations/changes leading to new data points that are similar to the ones they are derived from. The most\n",
            "common/popular technique is SMOTE (Synthetic Minority Oversampling technique)\n",
            "\n",
            "* Suppression: Though not recommended, we can drop off some features directly responsible for the imbalance.\n",
            "\n",
            "* Learning Fair Representation: Projecting the training examples to a subspace or plane minimizes the data\n",
            "imbalance.\n",
            "\n",
            "* Re-Weighting: We can assign some weights to each training example to reduce the imbalance in the data.\n",
            "\n",
            "**2. In-Processing:**\n",
            "\n",
            "* Regularisation: We can add score terms that measure the data imbalance in the loss function and therefore\n",
            "minimizing the loss function will also minimize the degree of imbalance concerning the score chosen which also\n",
            "indirectly minimizes other metrics that measure the degree of data imbalance.\n",
            "\n",
            "* Adversarial Debiasing: Here we use the adversarial notion to train the model where the discriminator tries\n",
            "to detect if there are signs of data imbalance in the predicted data by the generator and hence the generator\n",
            "learns to generate data that is less prone to imbalance.\n",
            "\n",
            "**3. Post-Processing:**\n",
            "* Odds-Equalization: Here we try to equalize the odds for the classes with respect to the data is imbalanced\n",
            "for correct imbalance in the trained model. Usually, the F1 score is a good choice, if both precision and\n",
            "recall scores are important\n",
            "\n",
            "* Choose appropriate performance metrics. For example, accuracy is not a correct metric to use when classes\n",
            "are imbalanced. Instead, use precision, recall, F1 score, and ROC curve.\n",
            "\n",
            "![Alt_text](https://github.com/youssefHosni/Data-Science-Interview-\n",
            "Questions/blob/main/Figures/Oversampling.png)\n",
            "\n",
            "### Q18: You are working on a clustering problem, what are different evaluation metrics that can be used, and\n",
            "how to choose between them? ###\n",
            "\n",
            "Answer:\n",
            "\n",
            "Clusters are evaluated based on some similarity or dissimilarity measure such as the distance between cluster\n",
            "points. If the clustering algorithm separates dissimilar observations and similar observations together, then\n",
            "it has performed well. The two most popular metrics evaluation metrics for clustering algorithms are the\n",
            "𝐒𝐢𝐥𝐡𝐨𝐮𝐞𝐭𝐭𝐞 𝐜𝐨𝐞𝐟𝐟𝐢𝐜𝐢𝐞𝐧𝐭 and 𝐃𝐮𝐧𝐧’𝐬 𝐈𝐧𝐝𝐞𝐱.\n",
            "\n",
            "𝐒𝐢𝐥𝐡𝐨𝐮𝐞𝐭𝐭𝐞 𝐜𝐨𝐞𝐟𝐟𝐢𝐜𝐢𝐞𝐧𝐭\n",
            "The Silhouette Coefficient is defined for each sample and is composed of two scores:\n",
            "a: The mean distance between a sample and all other points in the same cluster.\n",
            "b: The mean distance between a sample and all other points in the next nearest cluster.\n",
            "\n",
            "S = (b-a) / max(a,b)\n",
            "\n",
            "The 𝐒𝐢𝐥𝐡𝐨𝐮𝐞𝐭𝐭𝐞 𝐜𝐨𝐞𝐟𝐟𝐢𝐜𝐢𝐞𝐧𝐭 for a set of samples is given as the mean of the Silhouette Coefficient for each\n",
            "sample. The score is bounded between -1 for incorrect clustering and +1 for highly dense clustering. Scores\n",
            "around zero indicate overlapping clusters. The score is higher when clusters are dense and well separated,\n",
            "which relates to a standard concept of a cluster.\n",
            "\n",
            "Dunn’s Index\n",
            "\n",
            "Dunn’s Index (DI) is another metric for evaluating a clustering algorithm. Dunn’s Index is equal to the\n",
            "minimum inter-cluster distance divided by the maximum cluster size. Note that large inter-cluster distances\n",
            "(better separation) and smaller cluster sizes (more compact clusters) lead to a higher DI value. A higher DI\n",
            "implies better clustering. It assumes that better clustering means that clusters are compact and well-\n",
            "separated from other clusters.\n",
            "\n",
            "![Alt_text](https://github.com/youssefHosni/Data-Science-Interview-Questions/blob/main/Figures/Derivation-of-\n",
            "the-Overall-Silhouette-Coefficient-OverallSil.png)\n",
            "\n",
            "### Q19: What is the ROC curve and when should you use it? ###\n",
            "\n",
            "Answer:\n",
            "\n",
            "ROC curve, Receiver Operating Characteristic curve, is a graphical representation of the model's performance\n",
            "where we plot the True Positive Rate (TPR) against the False Positive Rate (FPR) for different threshold\n",
            "values, for hard classification, between 0 to 1 based on model output.\n",
            "\n",
            "This ROC curve is mainly used to compare two or more models as shown in the figure below. Now, it is easy to\n",
            "see that a reasonable model will always give FPR less (since it's an error) than TPR so, the curve hugs the\n",
            "upper left corner of the square box 0 to 1 on the TPR axis and 0 to 1 on the FPR axis.\n",
            "\n",
            "The more the AUC(area under the curve) for a model's ROC curve, the better the model in terms of prediction\n",
            "accuracy in terms of TPR and FPR.\n",
            "\n",
            "Here are some benefits of using the ROC Curve :\n",
            "\n",
            "* Can help prioritize either true positives or true negatives depending on your case study (Helps you visually\n",
            "choose the best hyperparameters for your case)\n",
            "\n",
            "* Can be very insightful when we have unbalanced datasets\n",
            "\n",
            "* Can be used to compare different ML models by calculating the area under the ROC curve (AUC)\n",
            "\n",
            "![Alt_text](https://github.com/youssefHosni/Data-Science-Interview-\n",
            "Questions/blob/main/Figures/Roc_curve.svg.png)\n",
            "\n",
            "### Q20: What is the difference between hard and soft voting classifiers in the context of ensemble learners?\n",
            "###\n",
            "\n",
            "Answer:\n",
            "\n",
            "* Hard Voting: We take into account the class predictions for each classifier and then classify an input based\n",
            "on the maximum votes to a particular class.\n",
            "\n",
            "* Soft Voting: We take into account the probability predictions for each class by each classifier and then\n",
            "classify an input to the class with maximum probability based on the average probability (averaged over the\n",
            "classifier's probabilities) for that class.\n",
            "\n",
            "![Alt_text](https://github.com/youssefHosni/Data-Science-Interview-\n",
            "Questions/blob/main/Figures/Hard%20Vs%20soft%20voting.png)\n",
            "\n",
            "### Q21: What is boosting in the context of ensemble learners discuss two famous boosting methods ###\n",
            "\n",
            "Answer:\n",
            "\n",
            "Boosting refers to any Ensemble method that can combine several weak learners into a strong learner. The\n",
            "general idea of most boosting methods is to train predictors sequentially, each trying to correct its\n",
            "predecessor.\n",
            "\n",
            "There are many boosting methods available, but by far the most popular are:\n",
            "\n",
            "* Adaptive Boosting: One way for a new predictor to correct its predecessor is to pay a bit more attention to\n",
            "the training instances that the predecessor under-fitted. This results in new predictors focusing more and\n",
            "more on the hard cases.\n",
            "* Gradient Boosting:  Another very popular Boosting algorithm is Gradient Boosting. Just like AdaBoost,\n",
            "Gradient Boosting works by sequentially adding predictors to an ensemble, each one correcting its predecessor.\n",
            "However, instead of tweaking the instance weights at every iteration as AdaBoost does, this method tries to\n",
            "fit the new predictor to the residual errors made by the previous predictor.\n",
            "\n",
            "![1661788022018](https://user-\n",
            "images.githubusercontent.com/72076328/187241588-6cc3166f-a3e0-46b9-a0ce-e3d9ef9f0228.jpg)\n",
            "\n",
            "### Q22: How can you evaluate the performance of a dimensionality reduction algorithm on your dataset? ###\n",
            "\n",
            "Answer:\n",
            "\n",
            "Intuitively, a dimensionality reduction algorithm performs well if it eliminates a lot of dimensions from the\n",
            "dataset without losing too much information. One way to measure this is to apply the reverse transformation\n",
            "and measure the reconstruction error. However, not all dimensionality reduction algorithms provide a reverse\n",
            "transformation.\n",
            "\n",
            "Alternatively, if you are using dimensionality reduction as a preprocessing step before another Machine\n",
            "Learning algorithm (e.g., a Random Forest classifier), then you can simply measure the performance of that\n",
            "second algorithm; if dimensionality reduction did not lose too much information, then the algorithm should\n",
            "perform just as well as when using the original dataset.\n",
            "\n",
            "### Q23: Define the curse of dimensionality and how to solve it. ###\n",
            "\n",
            "Answer:\n",
            "Curse of dimensionality represents the situation when the amount of data is too few to be represented in a\n",
            "high-dimensional space, as it will be highly scattered in that high-dimensional space and it becomes more\n",
            "probable that we overfit this data. If we increase the number of features, we are implicitly increasing model\n",
            "complexity and if we increase model complexity we need more data.\n",
            "\n",
            "Possible solutions are:\n",
            "Remove irrelevant features not discriminating classes correlated or features not resulting in much\n",
            "improvement, we can use:\n",
            "\n",
            "* Feature selection(select the most important ones).\n",
            "* Feature extraction(transform current feature dimensionality into a lower dimension preserving the most\n",
            "possible amount of information like PCA ).\n",
            "\n",
            "![Curse of dim'](https://user-\n",
            "images.githubusercontent.com/72076328/188653089-8999ea59-9511-4d52-baff-15a652e117a9.png)\n",
            "\n",
            "### Q24: In what cases would you use vanilla PCA, Incremental PCA, Randomized PCA, or Kernel PCA? ###\n",
            "\n",
            "\n",
            "Answer:\n",
            "\n",
            "Regular PCA is the default, but it works only if the dataset fits in memory. Incremental PCA is useful for\n",
            "large datasets that don't fit in memory, but it is slower than regular PCA, so if the dataset fits in memory\n",
            "you should prefer regular PCA. Incremental PCA is also useful for online tasks when you need to apply PCA on\n",
            "the fly, every time a new instance arrives. Randomized PCA is useful when you want to considerably reduce\n",
            "dimensionality and the dataset fits in memory; in this case, it is much faster than regular PCA. Finally,\n",
            "Kernel PCA is useful for nonlinear datasets.\n",
            "\n",
            "\n",
            "### Q25: Discuss two clustering algorithms that can scale to large datasets ###\n",
            "\n",
            "Answer:\n",
            "\n",
            "**Minibatch Kmeans:**  Instead of using the full dataset at each iteration, the algorithm\n",
            "is capable of using mini-batches, moving the centroids just slightly at each iteration.\n",
            "This speeds up the algorithm typically by a factor of 3 or 4 and makes it\n",
            "possible to cluster huge datasets that do not fit in memory. Scikit-Learn implements\n",
            "this algorithm in the MiniBatchKMeans class.\n",
            "\n",
            "**Balanced Iterative Reducing and Clustering using Hierarchies (BIRCH)** \n",
            "is a clustering algorithm that can cluster large datasets by first generating a small and compact summary of\n",
            "the large dataset that retains as much information as possible. This smaller summary is then clustered instead\n",
            "of clustering the larger dataset.\n",
            "\n",
            "### Q26: Do you need to scale your data if you will be using the SVM classifier and discus your answer ###\n",
            "Answer:\n",
            "Yes, feature scaling is required for SVM and all margin-based classifiers since the optimal hyperplane (the\n",
            "decision boundary) is dependent on the scale of the input features. In other words, the distance between two\n",
            "observations will differ for scaled and non-scaled cases, leading to different models being generated.\n",
            "\n",
            "This can be seen in the figure below, when the features have different scales, we can see that the decision\n",
            "boundary and the support vectors are only classifying the X1 features without taking into consideration the X0\n",
            "feature, however after scaling the data to the same scale the decision boundaries and support vectors are\n",
            "looking much better and the model is taking into account both features.\n",
            "\n",
            "To scale the data, normalization, and standardization are the most popular approaches.\n",
            "![SVM scaled Vs non scaled](https://user-\n",
            "images.githubusercontent.com/72076328/192571498-4a939472-7bb1-4bf2-963f-a6e6394802ba.png)\n",
            "\n",
            "### Q27: What are Loss Functions and Cost Functions? Explain the key Difference Between them. ###\n",
            "\n",
            "Answer:\n",
            "The loss function is the measure of the performance of the model on a single training example, whereas the\n",
            "cost function is the average loss function over all training examples or across the batch in the case of mini-\n",
            "batch gradient descent.\n",
            "\n",
            "Some examples of loss functions are Mean Squared Error, Binary Cross Entropy, etc.\n",
            "\n",
            "Whereas, the cost function is the average of the above loss functions over training examples.\n",
            "\n",
            "### Q28: What is the importance of batch in machine learning and explain some batch-dependent gradient descent\n",
            "algorithms? ###\n",
            "\n",
            "Answer:\n",
            "In the memory, the dataset can load either completely at once or in the form of a set. If we have a huge size\n",
            "of the dataset, then loading the whole data into memory will reduce the training speed, hence batch term is\n",
            "introduced.\n",
            "\n",
            "Example: image data contains 1,00,000 images, we can load this into 3125 batches where 1 batch = 32 images. So\n",
            "instead of loading the whole 1,00,000 images in memory, we can load 32 images 3125 times which requires less\n",
            "memory.\n",
            "\n",
            "In summary, a batch is important in two ways: (1) Efficient memory consumption. (2) Improve training speed.\n",
            "\n",
            "There are 3 types of gradient descent algorithms based on batch size: (1) Stochastic gradient descent (2)\n",
            "Batch gradient descent (3) Mini Batch gradient descent\n",
            "\n",
            "If the whole data is in a single batch, it is called batch gradient descent. If the single data points are\n",
            "equal to one batch i.e. number of batches = number of data instances, it is called stochastic gradient\n",
            "descent. If the number of batches is less than the number of data points or greater than 1, it is known as\n",
            "mini-batch gradient descent.\n",
            "\n",
            "### Q29: What are the different methods to split a tree in a decision tree algorithm? ###\n",
            "\n",
            "Answer:\n",
            "\n",
            "Decision trees can be of two types regression and classification.\n",
            "For classification, classification accuracy created a lot of instability. So the following loss functions are\n",
            "used:\n",
            "- Gini's Index\n",
            "Gini impurity is used to predict the likelihood of a randomly chosen example being incorrectly classified by a\n",
            "particular node. It’s referred to as an “impurity” measure because it demonstrates how the model departs from\n",
            "a simple division.\n",
            "\n",
            "- Cross-entropy or Information Gain\n",
            "Information gain refers to the process of identifying the most important features/attributes that convey the\n",
            "most information about a class. The entropy principle is followed with the goal of reducing entropy from the\n",
            "root node to the leaf nodes. Information gain is the difference in entropy before and after splitting, which\n",
            "describes the impurity of in-class items.\n",
            "\n",
            "\n",
            "For regression, the good old mean squared error serves as a good loss function which is minimized by splits of\n",
            "the input features and predicting the mean value of the target feature on the subspaces resulting from the\n",
            "split. But finding the split that results in the minimum possible residual sum of squares is computationally\n",
            "infeasible, so a greedy top-down approach is taken i.e. the splits are made at a level from top to down which\n",
            "results in maximum reduction of RSS. We continue this until some maximum depth or number of leaves is\n",
            "attained.\n",
            "\n",
            "### Q30: Why boosting is a more stable algorithm as compared to other ensemble algorithms? ###\n",
            "\n",
            "Answer:\n",
            "\n",
            "Boosting algorithms focus on errors found in previous iterations until they become obsolete. Whereas in\n",
            "bagging there is no corrective loop. That’s why boosting is a more stable algorithm compared to other ensemble\n",
            "algorithms.\n",
            "\n",
            "### Q31: What is active learning and discuss one strategy of it? ###\n",
            "\n",
            "Answer:\n",
            "Active learning is a special case of machine learning in which a learning algorithm can interactively query a\n",
            "user (or some other information source) to label new data points with the desired outputs. In statistics\n",
            "literature, it is sometimes referred to as optimal experimental design.\n",
            "\n",
            "1. Stream-based sampling\n",
            "In stream-based selective sampling, unlabelled data is continuously fed to an active learning system, where\n",
            "the learner decides whether to send the same to a human oracle or not based on a predefined learning strategy.\n",
            "This method is apt in scenarios where the model is in production and the data sources/distributions vary over\n",
            "time.\n",
            "\n",
            "2. Pool-based sampling\n",
            "In this case, the data samples are chosen from a pool of unlabelled data based on the informative value scores\n",
            "and sent for manual labeling. Unlike stream-based sampling, oftentimes, the entire unlabelled dataset is\n",
            "scrutinized for the selection of the best instances.\n",
            "\n",
            "![1669836673164](https://user-\n",
            "images.githubusercontent.com/72076328/204896144-43b2181a-d9ce-471b-95d0-44c0f7bb3025.jpg)\n",
            "\n",
            "### Q32: What are the different approaches to implementing recommendation systems? ###\n",
            "Answer:\n",
            "1. 𝐂𝐨𝐧𝐭𝐞𝐧𝐭-𝐁𝐚𝐬𝐞𝐝 𝐅𝐢𝐥𝐭𝐞𝐫𝐢𝐧𝐠: Content-Based Filtering depends on similarities of items and users' past\n",
            "activities on the website to recommend any product or service.\n",
            "\n",
            "This filter helps in avoiding a cold start for any new products as it doesn't rely on other users' feedback,\n",
            "it can recommend products based on similarity factors. However, content-based filtering needs a lot of domain\n",
            "knowledge so that the recommendations made are 100 percent accurate.\n",
            "\n",
            "2. 𝐂𝐨𝐥𝐥𝐚𝐛𝐨𝐫𝐚𝐭𝐢𝐯𝐞-𝐁𝐚𝐬𝐞𝐝 𝐅𝐢𝐥𝐭𝐞𝐫𝐢𝐧𝐠: The primary job of a collaborative filtering system is to overcome the\n",
            "shortcomings of content-based filtering.\n",
            "\n",
            "So, instead of focusing on just one user, the collaborative filtering system focuses on all the users and\n",
            "clusters them according to their interests.\n",
            "\n",
            "Basically, it recommends a product 'x' to user 'a' based on the interest of user 'b'; users 'a' and 'b' must\n",
            "have had similar interests in the past, which is why they are clustered together.\n",
            "\n",
            "The domain knowledge that is required for collaborative filtering is less, recommendations made are more\n",
            "accurate and it can adapt to the changing tastes of users over time. However, collaborative filtering faces\n",
            "the problem of a cold start as it heavily relies on feedback or activity from other users.\n",
            "\n",
            "3. 𝐇𝐲𝐛𝐫𝐢𝐝 𝐟𝐢𝐥𝐭𝐞𝐫𝐢𝐧𝐠:  A mixture of content and collaborative methods. Uses descriptors and interactions.\n",
            "\n",
            "More modern approaches typically fall into the hybrid filtering category and tend to work in two stages:\n",
            "\n",
            "1). A candidate generation phase where we coarsely generate candidates from a corpus of hundreds of thousands,\n",
            "millions, or billions of items down to a few hundred or thousand\n",
            "\n",
            "2) A ranking phase where we re-rank the candidates into a final top-n set to be shown to the user. Some\n",
            "systems employ multiple candidate generation methods and rankers.\n",
            "\n",
            "### Q33: What are the evaluation metrics that can be used for multi-label classification? ###\n",
            "\n",
            "Answer:\n",
            "\n",
            "Multi-label classification is a type of classification problem where each instance can be assigned to multiple\n",
            "classes or labels simultaneously.\n",
            "\n",
            "The evaluation metrics for multi-label classification are designed to measure the performance of a multi-label\n",
            "classifier in predicting the correct set of labels for each instance.\n",
            "Some commonly used evaluation metrics for multi-label classification are:\n",
            "\n",
            "1. Hamming Loss: Hamming Loss is the fraction of labels that are incorrectly predicted. It is defined as the\n",
            "average number of labels that are predicted incorrectly per instance.\n",
            "\n",
            "2. Accuracy: Accuracy is the fraction of instances that are correctly predicted. In multi-label\n",
            "classification, accuracy is calculated as the percentage of instances for which all labels are predicted\n",
            "correctly.\n",
            "\n",
            "3. Precision, Recall, F1-Score: These metrics can be applied to each label separately, treating the\n",
            "classification of each label as a separate binary classification problem. Precision measures the proportion of\n",
            "predicted positive labels that are correct, recall measures the proportion of actual positive labels that are\n",
            "correctly predicted, and F1-score is the harmonic mean of precision and recall.\n",
            "\n",
            "4. Macro-F1, Micro-F1: Macro-F1 and Micro-F1 are two types of F1-score metrics that take into account the\n",
            "label imbalance in the dataset. Macro-F1 calculates the F1-score for each label and then averages them, while\n",
            "Micro-F1 calculates the overall F1-score by aggregating the true positive, false positive, and false negative\n",
            "counts across all labels.\n",
            "\n",
            "There are other metrics that can be used such as:\n",
            "* Precision at k (P@k)\n",
            "* Average precision at k (AP@k)\n",
            "* Mean average precision at k (MAP@k)\n",
            "\n",
            "\n",
            "### Q34: What is the difference between concept and data drift and how to overcome each of them? ###\n",
            "\n",
            "Answer:\n",
            "\n",
            "Concept drift and data drift are two different types of problems that can occur in machine learning systems.\n",
            "\n",
            "Concept drift refers to changes in the underlying relationships between the input data and the target variable\n",
            "over time. This means that the distribution of the data that the model was trained on no longer matches the\n",
            "distribution of the data it is being tested on. For example, a spam filter model that was trained on emails\n",
            "from several years ago may not be as effective at identifying spam emails from today because the language and\n",
            "tactics used in spam emails may have changed.\n",
            "\n",
            "Data drift, on the other hand, refers to changes in the input data itself over time. This means that the\n",
            "values of the input feature that the model was trained on no longer match the values of the input features in\n",
            "the data it is being tested on. For example, a model that was trained on data from a particular geographical\n",
            "region may not be as effective at predicting outcomes for data from a different region.\n",
            "\n",
            "To overcome concept drift, one approach is to use online learning methods that allow the model to adapt to new\n",
            "data as it arrives. This involves continually training the model on the most recent data while using\n",
            "historical data to maintain context. Another approach is to periodically retrain the model using a\n",
            "representative sample of the most recent data.\n",
            "\n",
            "To overcome data drift, one approach is to monitor the input data for changes and retrain the model when\n",
            "significant changes are detected. This may involve setting up a monitoring system that alerts the user when\n",
            "the data distribution changes beyond a certain threshold.\n",
            "\n",
            "Another approach is to preprocess the input data to remove or mitigate the effects of the features changing\n",
            "over time so that the model can continue learning from the remaining features.\n",
            "![ezgif com-webp-to-jpg (7)](https://user-images.githubusercontent.com/72076328/221916192-7a9fcf21-8e5f-4ddc-\n",
            "bd90-ef1bdabf1d3f.jpg)\n",
            "\n",
            "### Q35: Can you explain the ARIMA model and its components? ###\n",
            "Answer:\n",
            "The ARIMA model, which stands for Autoregressive Integrated Moving Average, is a widely used time series\n",
            "forecasting model. It combines three key components: Autoregression (AR), Differencing (I), and Moving Average\n",
            "(MA).\n",
            "\n",
            "* Autoregression (AR):\n",
            "The autoregressive component captures the relationship between an observation in a time series and a certain\n",
            "number of lagged observations. It assumes that the value at a given time depends linearly on its own previous\n",
            "values. The \"p\" parameter in ARIMA(p, d, q) represents the order of autoregressive terms. For example,\n",
            "ARIMA(1, 0, 0) refers to a model with one autoregressive term.\n",
            "\n",
            "* Differencing (I):\n",
            "Differencing is used to make a time series stationary by removing trends or seasonality. It calculates the\n",
            "difference between consecutive observations to eliminate any non-stationary behavior. The \"d\" parameter in\n",
            "ARIMA(p, d, q) represents the order of differencing. For instance, ARIMA(0, 1, 0) indicates that differencing\n",
            "is applied once.\n",
            "\n",
            "* Moving Average (MA):\n",
            "The moving average component takes into account the dependency between an observation and a residual error\n",
            "from a moving average model applied to lagged observations. It assumes that the value at a given time depends\n",
            "linearly on the error terms from previous time steps. The \"q\" parameter in ARIMA(p, d, q) represents the order\n",
            "of the moving average terms. For example, ARIMA(0, 0, 1) signifies a model with one moving average term.\n",
            "\n",
            "By combining these three components, the ARIMA model can capture both autoregressive patterns, temporal\n",
            "dependencies, and stationary behavior in a time series. The parameters p, d, and q are typically determined\n",
            "through techniques like the Akaike Information Criterion (AIC) or Bayesian Information Criterion (BIC).\n",
            "\n",
            "It's worth noting that there are variations of the ARIMA model, such as SARIMA (Seasonal ARIMA), which\n",
            "incorporates additional seasonal components for modeling seasonal patterns in the data.\n",
            "\n",
            "ARIMA models are widely used in forecasting applications, but they do make certain assumptions about the\n",
            "underlying data, such as linearity and stationarity. It's important to validate these assumptions and adjust\n",
            "the model accordingly if they are not met.\n",
            "![1-1](https://github.com/youssefHosni/Data-Science-Interview-Questions-\n",
            "Answers/assets/72076328/12707951-bdf5-4cd1-9efd-c60c465007a3)\n",
            "\n",
            "### Q36: What are the assumptions made by the ARIMA model? ###\n",
            "Answer:\n",
            "\n",
            "The ARIMA model makes several assumptions about the underlying time series data. These assumptions are\n",
            "important to ensure the validity and accuracy of the model's results. Here are the key assumptions:\n",
            "\n",
            "Stationarity: The ARIMA model assumes that the time series is stationary. Stationarity means that the\n",
            "statistical properties of the data, such as the mean and variance, remain constant over time. This assumption\n",
            "is crucial for the autoregressive and moving average components to hold. If the time series is non-stationary,\n",
            "differencing (the \"I\" component) is applied to transform it into a stationary series.\n",
            "\n",
            "Linearity: The ARIMA model assumes that the relationship between the observations and the lagged values is\n",
            "linear. It assumes that the future values of the time series can be modeled as a linear combination of past\n",
            "values and error terms.\n",
            "\n",
            "No Autocorrelation in Residuals: The ARIMA model assumes that the residuals (the differences between the\n",
            "predicted values and the actual values) do not exhibit any autocorrelation. In other words, the errors are not\n",
            "correlated with each other.\n",
            "\n",
            "Normally Distributed Residuals: The ARIMA model assumes that the residuals follow a normal distribution with a\n",
            "mean of zero. This assumption is necessary for statistical inference, parameter estimation, and hypothesis\n",
            "testing.\n",
            "\n",
            "It's important to note that while these assumptions are commonly made in ARIMA modeling, they may not always\n",
            "hold in real-world scenarios. It's essential to assess the data and, if needed, apply transformations or\n",
            "consider alternative models that relax some of these assumptions. Additionally, diagnostics tools, such as\n",
            "residual analysis and statistical tests, can help evaluate the adequacy of the assumptions and the model's fit\n",
            "to the data.\n",
            "' metadata={'source': './ds_interview_ques.txt'}\n"
          ]
        }
      ],
      "source": [
        "print(wrap_text_preserve_newlines(str(documents[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLOATUY0x8uF"
      },
      "source": [
        "## Use the `RecursiveCharacterTextSplitter` from LangChain to split documents into chunks based on different separators, with a fallback mechanism:\n",
        "- **`chunk_size`**: Maximum size of each chunk (1000 characters).\n",
        "- **`chunk_overlap`**: Number of overlapping characters between chunks (10).\n",
        "- **`separators`**: List of separators to split the text, including newlines, spaces, and empty strings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4ojKVb8_7SqH"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Try to split by sentences, then fallback to characters if necessary\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=10,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")\n",
        "docs = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9K2KQef6_dJ",
        "outputId": "4cceb861-b096-4a91-931c-24f45fe7e216"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXzFrpci7Ahp",
        "outputId": "8c91d91e-b587-428c-fba8-c2533f7b2b06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': './ds_interview_ques.txt'}, page_content='Answer:\\n\\nLogistic regression is used to calculate the probability of occurrence of an event in the form of a dependent output variable based on independent input variables. Logistic regression is commonly used to estimate the probability that an instance belongs to a particular class. If the probability is bigger than 0.5 then it will belong to that class (positive) and if it is below 0.5 it will belong to the other class. This will make it a binary classifier.\\n\\nIt is important to remember that the Logistic regression isn\\'t a classification model, it\\'s an ordinary type of regression algorithm, and it was developed and used before machine learning, but it can be used in classification when we put a threshold to determine specific categories\"\\n\\nThere is a lot of classification applications to it:\\n\\nClassify email as spam or not, To identify whether the patient is healthy or not, and so on.')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[23]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9W6l_OVpyR7-"
      },
      "source": [
        "## Create Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608,
          "referenced_widgets": [
            "8e02f7cdeda6401e8a7e6672c6da353a",
            "e90b52280df34d1d9a3858089b3c6c0b",
            "a473df76de9d4c3084cd9d05fd007333",
            "22dcb2860b0748198f6519d67693bada",
            "af6a60683b7f429da7a352f86c321ae6",
            "11f728342557489c9d4a816a72dc74ae",
            "217650c1965f49bdb61b385155ab634e",
            "6e409424203940a48002d50d0e28e6a3",
            "d24e603b07a8492fbe3a9b0819925bba",
            "6081002fb30b436d9332c10185253d00",
            "5258001d87a44ea2baaf5dfa0c9ac6ff",
            "c218174a7afc4a719e976c6d316c2744",
            "93f5b37935f349a7b11539d5c563dfce",
            "383705f97b7b404b8dc47907c5db1237",
            "242084c4a34047888c3bf19d4630cae1",
            "b4ea639277e6449b8b7286a645472740",
            "8d945524f3494f32a73e62b26c4d1c44",
            "f3f0d17edfaf4e8cab19da2a2e0c016e",
            "29c960fbfd1c4854b4c382ccb17eef48",
            "7d460d8af99a462fa7542da09cc5871b",
            "2bf0ab01830448bfa90b5d318378fc2e",
            "9baac9d2a18b4dae8c85f3f095695072",
            "7f9ebe3075af4ede9106300ccff73ab2",
            "4cab9d877ccb48dfb59a34261dd93473",
            "7de6670c31fc42cbb0f4cb9dcd2ebf14",
            "53466d29ffff400294f7ce596128d917",
            "7636e15ce00f447b9381d5747e2fcccd",
            "f886c190c31947e5a5eeed6a3659dbe1",
            "a442b2fb2c3041d393b0685a44ddaa76",
            "3f411b816a624c1fb16dd251bb4e7b9c",
            "de0c678f4cb54774afd1d62283d4cfe4",
            "d4b4aff7168c4764a99ac351c4a48b94",
            "6d23a2dc763944559834a116b39aec35",
            "494879bd57914e7f902054dc96f3f70e",
            "3335ae171b9c4514ba146dd1f80bfae5",
            "746fc06feac94a74a506cb11f580000b",
            "ff96fbfd4723499e86b797c4856f0fd4",
            "1427470bce6c488a98f92f1f7e71c3ed",
            "4a364a9cf9e3485aaf98d0776bbe5498",
            "bc5de9796bda4f7c9120fd7ea72b359f",
            "40f914a9eb0c43cb82c383d8af26c54e",
            "198522a4054b4be4a662f5a5993aa18a",
            "f85dd60965154b29a61229ef9a609e88",
            "1783b769c2b447278fc931a8d936ddbd",
            "32c63b97b356412abadabc341338525f",
            "2101bff0bdf945e8a70777cb3e11c704",
            "be6fa304dfc24320951b7a55885146c9",
            "3a0a686153ca4cd5b03c75ce5c4ed7f9",
            "0f339ebd56024c92abc76e4af9c723bd",
            "7cb8708664a84d4fa2be931c0992ed5d",
            "82470d3aad9b4342aedecb31a79bf967",
            "53a31390b6404b598f282d76aa1691c3",
            "464cdffb4f1b4c68984edc8e943c0b72",
            "1ba601eafbc64743a434b4817da3353b",
            "6dee24c4e4374c75916c48cef79f8fdc",
            "ae9a131048b7467ca4ca9a20703e2def",
            "b971ca5cee8f41b193798d7c24c6bd95",
            "d407736189a34420bb6e89a3ba88ea11",
            "641839ad713f46e8acbbdb8874c31866",
            "6bc509065ee849d79e8f805a3a08ffdb",
            "4466b6fb80d54dd992c2db69aedd7acf",
            "0362711877ac4f06ab4c4a24ce21f120",
            "bf4369e32db041c8a81fe28e8641b80c",
            "4173021814eb494695a17d78860c5bd1",
            "fb066d3c51dc455c83349c5240e63c9f",
            "26c1f6bdb5814b1f8a789077115c6064",
            "824fec9487534fb29beb9791f9113c42",
            "5fb03d9e41e44f6cad5df860ee29464c",
            "b7987270f7cb443683fa7baa1f07a8f3",
            "9c270f2d56fa41c79f02d029fa4d2abc",
            "0e63c3f6f4934406ac63a6c2b23d2d46",
            "36a5a86d54a94b27bc5e36df037d0fe8",
            "84a1d9b0e98f42d19169c32e8058c437",
            "407f95a5d9534d59aab305bf4c2f99d2",
            "fb8df2a8e1bf4140810617309cfe21f4",
            "e952f7424060456fae42e0ddcb1806fc",
            "3b0cae9c02774c1495535eff8bfb2825",
            "64b7b5079dfd478aad67a64ed65ce4b2",
            "7cf2e9157f45405fb23c139b1ce7632c",
            "3a0256002c60456fb02862a53588646c",
            "2f7772e31e224e2abd54c7a92739fd6f",
            "51eb44a43dd543249f72445dc78611cf",
            "d078311d561c4a74920d8823aa0a444b",
            "38d2ed6f857e42a1a59307328ac7ba6a",
            "3683dba1a9bb448eb153cb548b2e3b03",
            "6042ca8837244dc4a93f42dd8d08e6d0",
            "4c54c9781c814dfea253ed5ffd850f69",
            "07d59b3d6a52406f9967ff7278641651",
            "301f530a4547431e8014d2f07e7bd5a0",
            "77640ea0fc8549908007b162e78248ce",
            "32877889617d4b55ba84eaa701946ec9",
            "b84156ad05194f5fbfcd9fddfa53e0c7",
            "b007990024ae4dbaaff6987d36dcf5d4",
            "400be2a4dc414538bb2b0a27a85e7768",
            "ea12981fd3824e1192d4251d85979f19",
            "11fea400cb35482094e57d59feeb99fa",
            "e3d15dc4f55644f4a132a76977c789e5",
            "3bbce4b4e4934e61b8579010a03ae341",
            "35b7d80a30974ddab219d889613671c1",
            "320749866871494aa3a83127c9eba444",
            "68a0c8cd1ca049fab78f4f8c2503dc45",
            "ce4e2c4323c840248030bd6b789dd549",
            "235a8d099e394dddb4c5ca41df967aff",
            "f0a907c9ac6b4cb4a4d5bcbaa08653a3",
            "987446d5abc54e1ca87f592e4c1e170f",
            "01cb43bbc401453bbc59590358b43f0a",
            "f86899986a50431db7abbe09afe97d67",
            "d7e3c121b6534ea68fef30e3118bcb0f",
            "5280dc0dbfd44cb68b38ce3fd7ab5bc4",
            "b140d71a471a44d6ae6d804e3bce2510",
            "31c3087a9f374bf287f02ec24e46fff9",
            "880020f8ed0d4332a9eaee27b1dbc284",
            "8ca76586462549978679c4f3857df894",
            "18138765bf7f455884fb62131bb78855",
            "50dd6e4c5c7e47229ddc7bd49232485d",
            "a523c6cd4ed54c1ea8a34b74c2baee54",
            "eeb9655343be4d1daab298a48e56ccd8",
            "7f0aef7370744e5b8783f0f03bd79b0f",
            "c3ad0a77fcf24ba8b4fc380f7ee7364d",
            "3dba16b5cf2e454085d8f5aa95ca774e",
            "f92ce6be8e784b7a98ca8798c958ddd2"
          ]
        },
        "id": "uB3lgN9o7bYd",
        "outputId": "6f0b82db-5b60-4681-9626-eaa02ddf39f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "<ipython-input-11-a153ccf152c6>:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  embeddings = HuggingFaceEmbeddings()\n",
            "<ipython-input-11-a153ccf152c6>:2: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  embeddings = HuggingFaceEmbeddings()\n",
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e02f7cdeda6401e8a7e6672c6da353a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c218174a7afc4a719e976c6d316c2744",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f9ebe3075af4ede9106300ccff73ab2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "494879bd57914e7f902054dc96f3f70e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32c63b97b356412abadabc341338525f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae9a131048b7467ca4ca9a20703e2def",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "824fec9487534fb29beb9791f9113c42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64b7b5079dfd478aad67a64ed65ce4b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "301f530a4547431e8014d2f07e7bd5a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "320749866871494aa3a83127c9eba444",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31c3087a9f374bf287f02ec24e46fff9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgtvGyxNyt4f"
      },
      "source": [
        "## Create a **FAISS** vector store **(Database)** from documents using embeddings and perform a similarity search with a query to find relevant documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "neaoq4f17eXp"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "db = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "query = \"Mention three ways to make your model robust to outliers.\"\n",
        "docs = db.similarity_search(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE-sFiS8zUqS",
        "outputId": "cac3dd07-d3ff-4110-c6d4-c99359385983"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './ds_interview_ques.txt'}, page_content='-------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n## Questions & Answers ##\\n\\n### Q1: Mention three ways to make your model robust to outliers. ###\\n\\nInvestigating the outliers is always the first step in understanding how to treat them. After you understand the nature of why the outliers occurred you can apply one of the several methods mentioned [here](https://365datascience.com/career-advice/job-interview-tips/machine-learning-interview-questions-and-answers/#11:~:text=for%20large%20datasets.-,Bonus%20Question%3A%20Discuss%20how%20to%20make%20your%20model%20robust%20to%20outliers.,-There%20are%20several).\\n\\n### Q2: Describe the motivation behind random forests and mention two reasons why they are better than individual decision trees. ###'),\n",
              " Document(metadata={'source': './ds_interview_ques.txt'}, page_content='## Questions ##\\n* [Q1: Mention three ways to make your model robust to outliers?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q1-mention-three-ways-to-make-your-model-robust-to-outliers)\\n* [Q2: Describe the motivation behind random forests and mention two reasons why they are better than individual decision trees?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q2-describe-the-motivation-behind-random-forests-and-mention-two-reasons-why-they-are-better-than-individual-decision-trees)'),\n",
              " Document(metadata={'source': './ds_interview_ques.txt'}, page_content='* [Q5: What are the Bias and Variance in a Machine Learning Model and explain the bias-variance trade-off?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q5-what-are-the-bias-and-variance-in-a-machine-learning-model-and-explain-the-bias-variance-trade-off)\\n* [Q6: Mention three ways to handle missing or corrupted data in a dataset?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q6-mention-three-ways-to-handle-missing-or-corrupted-data-in-a-dataset)'),\n",
              " Document(metadata={'source': './ds_interview_ques.txt'}, page_content='Answer:\\n\\nThe goal of any supervised machine learning model is to estimate the mapping function (f) that predicts the target variable (y) given input (x). The prediction error can be broken down into three parts:\\nThe rest of the answer is [here](https://365datascience.com/career-advice/job-interview-tips/machine-learning-interview-questions-and-answers/#2:~:text=8.%20What%20are%20the%20bias%20and%20variance%20in%20a%20machine%20learning%20model%20and%20explain%20the%20bias%2Dvariance%20trade%2Doff%3F)\\n\\n### Q6: Mention three ways to handle missing or corrupted data in a dataset. ###\\n\\nAnswer:')]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq9ApIJh7x-D"
      },
      "source": [
        "## Create LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt9Jsl5970OX",
        "outputId": "bc81a1a6-6004-4613-a247-248a6b82eaac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-a8889c6a2112>:11: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
            "stuff: https://python.langchain.com/v0.2/docs/versions/migrating_chains/stuff_docs_chain\n",
            "map_reduce: https://python.langchain.com/v0.2/docs/versions/migrating_chains/map_reduce_chain\n",
            "refine: https://python.langchain.com/v0.2/docs/versions/migrating_chains/refine_chain\n",
            "map_rerank: https://python.langchain.com/v0.2/docs/versions/migrating_chains/map_rerank_docs_chain\n",
            "\n",
            "See also guides on retrieval and question-answering here: https://python.langchain.com/v0.2/docs/how_to/#qa-with-rag\n",
            "  chain = load_qa_chain(GROQ_LLM, chain_type=\"stuff\")\n"
          ]
        }
      ],
      "source": [
        "import langchain_groq\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "\n",
        "GROQ_LLM = ChatGroq(\n",
        "            api_key=os.getenv(\"GROQ_API_KEY\"),\n",
        "            model=\"gemma2-9b-it\"\n",
        "        )\n",
        "\n",
        "# Load a QA chain with the specified language model and chain type for question answering.\n",
        "chain = load_qa_chain(GROQ_LLM, chain_type=\"stuff\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOkyBQZ2a_bG"
      },
      "source": [
        "## Q1.What is information gain and entropy in the context of decision trees?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "yjK9ZRvg702T",
        "outputId": "00567870-4712-4051-e9cc-29ee9e9ef7d8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Here\\'s a breakdown of information gain and entropy in the context of decision trees, based on the provided text:\\n\\n**Entropy**\\n\\n* **Measure of Impurity:**  Entropy essentially quantifies the disorder or uncertainty within a set of data points. In decision trees, it measures how mixed the classes are at a particular node. A node with high entropy means the data points are spread across many different classes, indicating higher uncertainty.\\n\\n* **Goal:** The goal of building a decision tree is to reduce entropy as you move down the tree. Each split (decision) should lead to nodes with lower entropy, meaning the data points are becoming more homogeneous (grouped into fewer, more distinct classes).\\n\\n**Information Gain**\\n\\n* **Measuring Split Effectiveness:** Information gain calculates how much the entropy *decreases* when you split the data based on a specific feature.\\n\\n* **Choosing the Best Split:**  Decision trees use information gain to determine the best feature to split on at each node. The feature that results in the largest reduction in entropy (the highest information gain) is chosen. This ensures that the tree is built in a way that progressively separates the data into more distinct classes.\\n\\n\\n**Analogy:**\\n\\nImagine a bag of mixed fruit (high entropy).  You want to sort them into separate piles (low entropy).\\n\\n* **Feature:**  The feature you choose to split on (e.g., color, size).\\n* **Split:**  Dividing the fruit based on the chosen feature (e.g., red apples separate from green apples).\\n* **Information Gain:** How much \"cleaner\" your piles become after the split (i.e., how much the overall entropy decreases).\\n\\n\\n\\nLet me know if you have any other questions! \\n'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"what is information gain and entropy in the context of decision trees?\"\n",
        "\n",
        "# Perform a similarity search in the FAISS vector store to retrieve relevant documents based on the query\n",
        "docs = db.similarity_search(query)\n",
        "\n",
        "# Use the QA chain to process the retrieved documents and generate an answer to the query\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPQs9aEF0in2"
      },
      "source": [
        "Here's a breakdown of information gain and entropy in the context of decision trees, based on the provided text:\n",
        "\n",
        "**Entropy**\n",
        "\n",
        "* **Measure of Impurity:**  Entropy essentially quantifies the disorder or uncertainty within a set of data points. In decision trees, it measures how mixed the classes are at a particular node. A node with high entropy means the data points are spread across many different classes, indicating higher uncertainty.\n",
        "\n",
        "* **Goal:** The goal of building a decision tree is to reduce entropy as you move down the tree. Each split (decision) should lead to nodes with lower entropy, meaning the data points are becoming more homogeneous (grouped into fewer, more distinct classes).\n",
        "\n",
        "**Information Gain**\n",
        "\n",
        "* **Measuring Split Effectiveness:** Information gain calculates how much the entropy *decreases* when you split the data based on a specific feature.\n",
        "\n",
        "* **Choosing the Best Split:**  Decision trees use information gain to determine the best feature to split on at each node. The feature that results in the largest reduction in entropy (the highest information gain) is chosen. This ensures that the tree is built in a way that progressively separates the data into more distinct classes.\n",
        "\n",
        "\n",
        "**Analogy:**\n",
        "\n",
        "Imagine a bag of mixed fruit (high entropy).  You want to sort them into separate piles (low entropy).\n",
        "\n",
        "* **Feature:**  The feature you choose to split on (e.g., color, size).\n",
        "* **Split:**  Dividing the fruit based on the chosen feature (e.g., red apples separate from green apples).\n",
        "* **Information Gain:** How much \"cleaner\" your piles become after the split (i.e., how much the overall entropy decreases).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xda7kkRTa01R",
        "outputId": "7bebff44-91d2-4ebd-db7b-0536731a150d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './ds_interview_ques.txt'}, page_content='### Q9: Explain what is information gain and entropy in the context of decision trees. ###\\nEntropy and Information Gain are two key metrics used in determining the relevance of decision-making when constructing a decision tree model and determining the nodes and the best way to split.\\n\\nThe idea of a decision tree is to divide the data set into smaller data sets based on the descriptive features until we reach a small enough set that contains data points that fall under one label.'),\n",
              " Document(metadata={'source': './ds_interview_ques.txt'}, page_content='Entropy is the measure of impurity, disorder, or uncertainty in a bunch of examples. Entropy controls how a Decision Tree decides to split the data.\\nInformation gain calculates the reduction in entropy or surprise from transforming a dataset in some way. It is commonly used in the construction of decision trees from a training dataset, by evaluating the information gain for each variable and selecting the variable that maximizes the information gain, which in turn minimizes the entropy and best splits the dataset into groups for effective classification.\\n\\n### Q10: Explain the linear regression model and discuss its assumption. ###\\nLinear regression is a supervised statistical model to predict dependent variable quantity based on independent variables.\\nLinear regression is a parametric model and the objective of linear regression is that it has to learn coefficients using the training data and predict the target value given only independent values.'),\n",
              " Document(metadata={'source': './ds_interview_ques.txt'}, page_content='- Cross-entropy or Information Gain\\nInformation gain refers to the process of identifying the most important features/attributes that convey the most information about a class. The entropy principle is followed with the goal of reducing entropy from the root node to the leaf nodes. Information gain is the difference in entropy before and after splitting, which describes the impurity of in-class items.\\n\\n\\nFor regression, the good old mean squared error serves as a good loss function which is minimized by splits of the input features and predicting the mean value of the target feature on the subspaces resulting from the split. But finding the split that results in the minimum possible residual sum of squares is computationally infeasible, so a greedy top-down approach is taken i.e. the splits are made at a level from top to down which results in maximum reduction of RSS. We continue this until some maximum depth or number of leaves is attained.'),\n",
              " Document(metadata={'source': './ds_interview_ques.txt'}, page_content=\"If the whole data is in a single batch, it is called batch gradient descent. If the single data points are equal to one batch i.e. number of batches = number of data instances, it is called stochastic gradient descent. If the number of batches is less than the number of data points or greater than 1, it is known as mini-batch gradient descent.\\n\\n### Q29: What are the different methods to split a tree in a decision tree algorithm? ###\\n\\nAnswer:\\n\\nDecision trees can be of two types regression and classification.\\nFor classification, classification accuracy created a lot of instability. So the following loss functions are used:\\n- Gini's Index\\nGini impurity is used to predict the likelihood of a randomly chosen example being incorrectly classified by a particular node. It’s referred to as an “impurity” measure because it demonstrates how the model departs from a simple division.\")]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Retrieved Document\n",
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsCMNVjdbHXY"
      },
      "source": [
        "## Q2.Explain the kernel trick in SVM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "Zcfw6FKi72Lo",
        "outputId": "2d6e4266-d9d9-43f3-f4d0-344cf86bd036"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The kernel trick in SVM allows us to perform calculations in a higher dimensional space without actually transforming the data into that space.  \\n\\nHere\\'s why we use it and how to choose a kernel:\\n\\n**Why use the kernel trick?**\\n\\n* **High dimensionality:**  Sometimes, data is not linearly separable in the original space.  By transforming it into a higher dimensional space, we might find a linear separation.  However, this transformation can be computationally expensive.\\n* **Efficiency:** The kernel trick calculates the dot product in the higher dimensional space directly, without performing the explicit transformation. This is much faster and more memory-efficient.\\n\\n**Choosing a kernel:**\\n\\nThe choice of kernel depends on the nature of the data and the problem:\\n\\n* **Linear kernel:**  Suitable for linearly separable data.\\n* **Polynomial kernel:**  Can capture non-linear relationships by increasing the dimensionality. The degree of the polynomial determines the complexity.\\n* **Radial basis function (RBF) kernel:**  Very flexible and commonly used. It creates a \"similarity\" measure between data points, allowing for complex decision boundaries.\\n* **Sigmoid kernel:**  Similar to the activation function in neural networks, often used in bioinformatics.\\n\\n**Common practice:**\\n\\nIt\\'s often necessary to experiment with different kernels and their parameters (e.g., the degree of the polynomial or the width of the RBF) to find the best performing kernel for a particular dataset. \\n\\n\\n'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"Explain the kernel trick in SVM. \"\n",
        "\n",
        "docs = db.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lqOONJY0c_P"
      },
      "source": [
        "The kernel trick in SVM allows us to perform calculations in a higher dimensional space without actually transforming the data into that space.  \n",
        "\n",
        "Here's why we use it and how to choose a kernel:\n",
        "\n",
        "**Why use the kernel trick?**\n",
        "\n",
        "* **High dimensionality:**  Sometimes, data is not linearly separable in the original space.  By transforming it into a higher dimensional space, we might find a linear separation.  However, this transformation can be computationally expensive.\n",
        "* **Efficiency:** The kernel trick calculates the dot product in the higher dimensional space directly, without performing the explicit transformation. This is much faster and more memory-efficient.\n",
        "\n",
        "**Choosing a kernel:**\n",
        "\n",
        "The choice of kernel depends on the nature of the data and the problem:\n",
        "\n",
        "* **Linear kernel:**  Suitable for linearly separable data.\n",
        "* **Polynomial kernel:**  Can capture non-linear relationships by increasing the dimensionality. The degree of the polynomial determines the complexity.\n",
        "* **Radial basis function (RBF) kernel:**  Very flexible and commonly used. It creates a \"similarity\" measure between data points, allowing for complex decision boundaries.\n",
        "* **Sigmoid kernel:**  Similar to the activation function in neural networks, often used in bioinformatics.\n",
        "\n",
        "**Common practice:**\n",
        "\n",
        "It's often necessary to experiment with different kernels and their parameters (e.g., the degree of the polynomial or the width of the RBF) to find the best performing kernel for a particular dataset.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL4Re7p6bZnt",
        "outputId": "aca84209-3f4d-46d9-bf0a-9ed027bd4514"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './ds_interview_ques.txt'}, page_content='Typically without the kernel trick, in order to calculate support vectors and support vector classifiers, we need first to transform data points one by one to the higher dimensional space, do the calculations based on SVM equations in the higher dimensional space, and then return the results. The ‘trick’ in the kernel trick is that we design the kernels based on some conditions as mathematical functions that are equivalent to a dot product in the higher dimensional space without even having to transform data points to the higher dimensional space. i.e. we can calculate support vectors and support vector classifiers in the same space where the data is provided which saves a lot of time and calculations.'),\n",
              " Document(metadata={'source': './ds_interview_ques.txt'}, page_content=\"**Nonparametric models** don't assume anything about the function from which the dataset was sampled. For these models, the number of parameters is not determined prior to training, thus they are free to generalize the model based on the data. Sometimes these models overfit themselves while generalizing. To generalize they need more data in comparison with Parametric Models. They are relatively more difficult to interpret compared to Parametric Models.\\n\\nEx. Decision Tree, Random Forest.\\n\\n### Q15: Explain the kernel trick in SVM. Why do we use it and how to choose what kernel to use? ###\\nAnswer:\\nKernels are used in SVM to map the original input data into a particular higher dimensional space where it will be easier to find patterns in the data and train the model with better performance.\"),\n",
              " Document(metadata={'source': './ds_interview_ques.txt'}, page_content='For eg.: If we have binary class data which form a ring-like pattern (inner and outer rings representing two different class instances) when plotted in 2D space, a linear SVM kernel will not be able to differentiate the two classes well when compared to an RBF (radial basis function) kernel, mapping the data into a particular higher dimensional space where the two classes are clearly separable.'),\n",
              " Document(metadata={'source': './ds_interview_ques.txt'}, page_content='* [Q14: Define and compare parametric and non-parametric models and give two examples for each of them?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q14-define-and-compare-parametric-and-non-parametric-models-and-give-two-examples-for-each-of-them)\\n* [Q15: Explain the kernel trick in SVM and why we use it and how to choose what kernel to use?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q15-explain-the-kernel-trick-in-svm-and-why-we-use-it-and-how-to-choose-what-kernel-to-use)')]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Retrieved Document\n",
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baMl8GRdbhwZ"
      },
      "source": [
        "## Q3. What are Loss Functions and Cost Functions?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "UdBaT_J878iB",
        "outputId": "12a55ebc-c766-4bba-a18b-995e01dd1e52"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The provided text explains the difference between loss functions and cost functions:\\n\\n* **Loss function:** Measures the performance of the model on a single training example.\\n* **Cost function:**  Averages the loss function over all training examples (or a batch of examples in mini-batch gradient descent). \\n\\n\\nLet me know if you have other questions. \\n'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"What are Loss Functions and Cost Functions?\"\n",
        "\n",
        "docs = db.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSpftC4B04ga"
      },
      "source": [
        "The provided text explains the difference between loss functions and cost functions:\n",
        "\n",
        "* **Loss function:** Measures the performance of the model on a single training example.\n",
        "* **Cost function:**  Averages the loss function over all training examples (or a batch of examples in mini-batch gradient descent).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m96MGsc3b8ya",
        "outputId": "c075b866-223f-48d5-e70b-109361a4236e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './ds_interview_ques.txt'}, page_content='To scale the data, normalization, and standardization are the most popular approaches.\\n![SVM scaled Vs non scaled](https://user-images.githubusercontent.com/72076328/192571498-4a939472-7bb1-4bf2-963f-a6e6394802ba.png)\\n\\n### Q27: What are Loss Functions and Cost Functions? Explain the key Difference Between them. ###\\n\\nAnswer:\\nThe loss function is the measure of the performance of the model on a single training example, whereas the cost function is the average loss function over all training examples or across the batch in the case of mini-batch gradient descent.\\n\\nSome examples of loss functions are Mean Squared Error, Binary Cross Entropy, etc.\\n\\nWhereas, the cost function is the average of the above loss functions over training examples.\\n\\n### Q28: What is the importance of batch in machine learning and explain some batch-dependent gradient descent algorithms? ###'),\n",
              " Document(metadata={'source': './ds_interview_ques.txt'}, page_content='### Q8: Explain briefly batch gradient descent, stochastic gradient descent, and mini-batch gradient descent. and what are the pros and cons for each of them? ###\\n\\nGradient descent is a generic optimization algorithm cable for finding optimal solutions to a wide range of problems. The general idea of gradient descent is to tweak parameters iteratively in order to minimize a cost function.\\n\\nBatch Gradient Descent:\\nIn Batch Gradient descent the whole training data is used to minimize the loss function by taking a step toward the nearest minimum by calculating the gradient (the direction of descent)\\n\\nPros:\\nSince the whole data set is used to calculate the gradient it will be stable and reach the minimum of the cost function without bouncing (if the learning rate is chosen cooreclty)\\n\\nCons:\\n\\nSince batch gradient descent uses all the training set to compute the gradient at every step, it will be very slow especially if the size of the training data is large.\\n\\n\\nStochastic Gradient Descent:'),\n",
              " Document(metadata={'source': './ds_interview_ques.txt'}, page_content='Entropy is the measure of impurity, disorder, or uncertainty in a bunch of examples. Entropy controls how a Decision Tree decides to split the data.\\nInformation gain calculates the reduction in entropy or surprise from transforming a dataset in some way. It is commonly used in the construction of decision trees from a training dataset, by evaluating the information gain for each variable and selecting the variable that maximizes the information gain, which in turn minimizes the entropy and best splits the dataset into groups for effective classification.\\n\\n### Q10: Explain the linear regression model and discuss its assumption. ###\\nLinear regression is a supervised statistical model to predict dependent variable quantity based on independent variables.\\nLinear regression is a parametric model and the objective of linear regression is that it has to learn coefficients using the training data and predict the target value given only independent values.'),\n",
              " Document(metadata={'source': './ds_interview_ques.txt'}, page_content='* [Q12: Define Precision, recall, and F1 and discuss the trade-off between them?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q12-define-precision-recall-and-f1-and-discuss-the-trade-off-between-them)\\n* [Q13: What are the differences between a model that minimizes squared error and the one that minimizes the absolute error? and in which cases each error metric would be more appropriate?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q13-what-are-the-differences-between-a-model-that-minimizes-squared-error-and-the-one-that-minimizes-the-absolute-error-and-in-which-cases-each-error-metric-would-be-more-appropriate)')]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Retrieved Document\n",
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c9iqOnKcMAa"
      },
      "source": [
        "## Q4. What are the assumptions made by the ARIMA model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "up7P9k7iZlm1",
        "outputId": "a1241746-7814-42a1-f9d6-d3b243f702db"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"The provided text lists the assumptions made by the ARIMA model:\\n\\n* **Normally Distributed Residuals:** The residuals follow a normal distribution with a mean of zero.\\n* **Stationarity:** The time series is stationary, meaning its statistical properties remain constant over time.\\n* **Linearity:** The relationship between observations and lagged values is linear.\\n* **No Autocorrelation in Residuals:** The residuals are not correlated with each other. \\n\\n\\nLet me know if you'd like more detail on any of these assumptions. \\n\""
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"What are the assumptions made by the ARIMA model?\"\n",
        "\n",
        "docs = db.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNKY9j_fZqUh"
      },
      "source": [
        "The provided text lists the assumptions made by the ARIMA model:\n",
        "\n",
        "* **Normally Distributed Residuals:** The residuals follow a normal distribution with a mean of zero.\n",
        "* **Stationarity:** The time series is stationary, meaning its statistical properties remain constant over time.\n",
        "* **Linearity:** The relationship between observations and lagged values is linear.\n",
        "* **No Autocorrelation in Residuals:** The residuals are not correlated with each other.\n",
        "\n",
        "\n",
        "Let me know if you'd like more detail on any of these assumptions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcuWDpefZoht",
        "outputId": "fd5b7746-e2d1-4962-bf48-13c63cca34da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './ds_interview_ques.txt'}, page_content=\"ARIMA models are widely used in forecasting applications, but they do make certain assumptions about the underlying data, such as linearity and stationarity. It's important to validate these assumptions and adjust the model accordingly if they are not met.\\n![1-1](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/assets/72076328/12707951-bdf5-4cd1-9efd-c60c465007a3)\\n\\n### Q36: What are the assumptions made by the ARIMA model? ###\\nAnswer:\\n\\nThe ARIMA model makes several assumptions about the underlying time series data. These assumptions are important to ensure the validity and accuracy of the model's results. Here are the key assumptions:\"),\n",
              " Document(metadata={'source': './ds_interview_ques.txt'}, page_content=\"Normally Distributed Residuals: The ARIMA model assumes that the residuals follow a normal distribution with a mean of zero. This assumption is necessary for statistical inference, parameter estimation, and hypothesis testing.\\n\\nIt's important to note that while these assumptions are commonly made in ARIMA modeling, they may not always hold in real-world scenarios. It's essential to assess the data and, if needed, apply transformations or consider alternative models that relax some of these assumptions. Additionally, diagnostics tools, such as residual analysis and statistical tests, can help evaluate the adequacy of the assumptions and the model's fit to the data.\"),\n",
              " Document(metadata={'source': './ds_interview_ques.txt'}, page_content='Stationarity: The ARIMA model assumes that the time series is stationary. Stationarity means that the statistical properties of the data, such as the mean and variance, remain constant over time. This assumption is crucial for the autoregressive and moving average components to hold. If the time series is non-stationary, differencing (the \"I\" component) is applied to transform it into a stationary series.\\n\\nLinearity: The ARIMA model assumes that the relationship between the observations and the lagged values is linear. It assumes that the future values of the time series can be modeled as a linear combination of past values and error terms.\\n\\nNo Autocorrelation in Residuals: The ARIMA model assumes that the residuals (the differences between the predicted values and the actual values) do not exhibit any autocorrelation. In other words, the errors are not correlated with each other.'),\n",
              " Document(metadata={'source': './ds_interview_ques.txt'}, page_content='* Moving Average (MA):\\nThe moving average component takes into account the dependency between an observation and a residual error from a moving average model applied to lagged observations. It assumes that the value at a given time depends linearly on the error terms from previous time steps. The \"q\" parameter in ARIMA(p, d, q) represents the order of the moving average terms. For example, ARIMA(0, 0, 1) signifies a model with one moving average term.\\n\\nBy combining these three components, the ARIMA model can capture both autoregressive patterns, temporal dependencies, and stationary behavior in a time series. The parameters p, d, and q are typically determined through techniques like the Akaike Information Criterion (AIC) or Bayesian Information Criterion (BIC).\\n\\nIt\\'s worth noting that there are variations of the ARIMA model, such as SARIMA (Seasonal ARIMA), which incorporates additional seasonal components for modeling seasonal patterns in the data.')]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Retrieved Document\n",
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXLxHFvTcS3N"
      },
      "source": [
        "## Q5. Discuss two clustering algorithms that can scale to large datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "pqM2fm2XcVlQ",
        "outputId": "55782953-54ce-4464-ed69-62d859579b26"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"The provided context discusses two clustering algorithms that can scale to large datasets: \\n\\n* **Minibatch Kmeans:** Uses mini-batches of data instead of the entire dataset at each iteration, speeding up the process and allowing for larger datasets.\\n* **BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies):** Creates a compact summary of the large dataset, clustering the summary instead of the full dataset.  \\n\\n\\nLet me know if you'd like more details about either of these algorithms. \\n\""
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"Discuss two clustering algorithms that can scale to large datasets.\"\n",
        "\n",
        "docs = db.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaemxA45ceGp"
      },
      "source": [
        "The provided context discusses two clustering algorithms that can scale to large datasets:\n",
        "\n",
        "* **Minibatch Kmeans:** Uses mini-batches of data instead of the entire dataset at each iteration, speeding up the process and allowing for larger datasets.\n",
        "* **BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies):** Creates a compact summary of the large dataset, clustering the summary instead of the full dataset.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC5MMzOJcnoD",
        "outputId": "c4481bad-7ecc-472f-8040-b755bae4a344"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './ds_interview_ques.txt'}, page_content='Answer:\\n\\n**Minibatch Kmeans:**  Instead of using the full dataset at each iteration, the algorithm\\nis capable of using mini-batches, moving the centroids just slightly at each iteration.\\nThis speeds up the algorithm typically by a factor of 3 or 4 and makes it\\npossible to cluster huge datasets that do not fit in memory. Scikit-Learn implements\\nthis algorithm in the MiniBatchKMeans class.\\n\\n**Balanced Iterative Reducing and Clustering using Hierarchies (BIRCH)**\\xa0\\nis a clustering algorithm that can cluster large datasets by first generating a small and compact summary of the large dataset that retains as much information as possible. This smaller summary is then clustered instead of clustering the larger dataset.'),\n",
              " Document(metadata={'source': './ds_interview_ques.txt'}, page_content='* [Q18: You are working on a clustering problem, what are different evaluation metrics that can be used, and how to choose between them?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q18-you-are-working-on-a-clustering-problem-what-are-different-evaluation-metrics-that-can-be-used-and-how-to-choose-between-them)\\n* [Q19: What is the ROC curve and when should you use it?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q19-what-is-the-roc-curve-and-when-should-you-use-it)'),\n",
              " Document(metadata={'source': './ds_interview_ques.txt'}, page_content='* Choose appropriate performance metrics. For example, accuracy is not a correct metric to use when classes are imbalanced. Instead, use precision, recall, F1 score, and ROC curve.\\n\\n![Alt_text](https://github.com/youssefHosni/Data-Science-Interview-Questions/blob/main/Figures/Oversampling.png)\\n\\n### Q18: You are working on a clustering problem, what are different evaluation metrics that can be used, and how to choose between them? ###\\n\\nAnswer:\\n\\nClusters are evaluated based on some similarity or dissimilarity measure such as the distance between cluster points. If the clustering algorithm separates dissimilar observations and similar observations together, then it has performed well. The two most popular metrics evaluation metrics for clustering algorithms are the 𝐒𝐢𝐥𝐡𝐨𝐮𝐞𝐭𝐭𝐞 𝐜𝐨𝐞𝐟𝐟𝐢𝐜𝐢𝐞𝐧𝐭 and 𝐃𝐮𝐧𝐧’𝐬 𝐈𝐧𝐝𝐞𝐱.'),\n",
              " Document(metadata={'source': './ds_interview_ques.txt'}, page_content='* [Q24: In what cases would you use vanilla PCA, Incremental PCA, Randomized PCA, or Kernel PCA?](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q24-in-what-cases-would-you-use-vanilla-pca-incremental-pca-randomized-pca-or-kernel-pca)\\n* [Q25: Discuss two clustering algorithms that can scale to large datasets](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/blob/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md#q25-discuss-two-clustering-algorithms-that-can-scale-to-large-datasets)')]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Retrieved Document\n",
        "docs"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01cb43bbc401453bbc59590358b43f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0362711877ac4f06ab4c4a24ce21f120": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07d59b3d6a52406f9967ff7278641651": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e63c3f6f4934406ac63a6c2b23d2d46": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f339ebd56024c92abc76e4af9c723bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11f728342557489c9d4a816a72dc74ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11fea400cb35482094e57d59feeb99fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1427470bce6c488a98f92f1f7e71c3ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1783b769c2b447278fc931a8d936ddbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18138765bf7f455884fb62131bb78855": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dba16b5cf2e454085d8f5aa95ca774e",
            "placeholder": "​",
            "style": "IPY_MODEL_f92ce6be8e784b7a98ca8798c958ddd2",
            "value": " 190/190 [00:00&lt;00:00, 8.06kB/s]"
          }
        },
        "198522a4054b4be4a662f5a5993aa18a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ba601eafbc64743a434b4817da3353b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2101bff0bdf945e8a70777cb3e11c704": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cb8708664a84d4fa2be931c0992ed5d",
            "placeholder": "​",
            "style": "IPY_MODEL_82470d3aad9b4342aedecb31a79bf967",
            "value": "config.json: 100%"
          }
        },
        "217650c1965f49bdb61b385155ab634e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22dcb2860b0748198f6519d67693bada": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6081002fb30b436d9332c10185253d00",
            "placeholder": "​",
            "style": "IPY_MODEL_5258001d87a44ea2baaf5dfa0c9ac6ff",
            "value": " 349/349 [00:00&lt;00:00, 22.7kB/s]"
          }
        },
        "235a8d099e394dddb4c5ca41df967aff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5280dc0dbfd44cb68b38ce3fd7ab5bc4",
            "placeholder": "​",
            "style": "IPY_MODEL_b140d71a471a44d6ae6d804e3bce2510",
            "value": " 239/239 [00:00&lt;00:00, 17.2kB/s]"
          }
        },
        "242084c4a34047888c3bf19d4630cae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bf0ab01830448bfa90b5d318378fc2e",
            "placeholder": "​",
            "style": "IPY_MODEL_9baac9d2a18b4dae8c85f3f095695072",
            "value": " 116/116 [00:00&lt;00:00, 7.62kB/s]"
          }
        },
        "26c1f6bdb5814b1f8a789077115c6064": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29c960fbfd1c4854b4c382ccb17eef48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bf0ab01830448bfa90b5d318378fc2e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f7772e31e224e2abd54c7a92739fd6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c54c9781c814dfea253ed5ffd850f69",
            "placeholder": "​",
            "style": "IPY_MODEL_07d59b3d6a52406f9967ff7278641651",
            "value": " 232k/232k [00:00&lt;00:00, 3.63MB/s]"
          }
        },
        "301f530a4547431e8014d2f07e7bd5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77640ea0fc8549908007b162e78248ce",
              "IPY_MODEL_32877889617d4b55ba84eaa701946ec9",
              "IPY_MODEL_b84156ad05194f5fbfcd9fddfa53e0c7"
            ],
            "layout": "IPY_MODEL_b007990024ae4dbaaff6987d36dcf5d4"
          }
        },
        "31c3087a9f374bf287f02ec24e46fff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_880020f8ed0d4332a9eaee27b1dbc284",
              "IPY_MODEL_8ca76586462549978679c4f3857df894",
              "IPY_MODEL_18138765bf7f455884fb62131bb78855"
            ],
            "layout": "IPY_MODEL_50dd6e4c5c7e47229ddc7bd49232485d"
          }
        },
        "320749866871494aa3a83127c9eba444": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68a0c8cd1ca049fab78f4f8c2503dc45",
              "IPY_MODEL_ce4e2c4323c840248030bd6b789dd549",
              "IPY_MODEL_235a8d099e394dddb4c5ca41df967aff"
            ],
            "layout": "IPY_MODEL_f0a907c9ac6b4cb4a4d5bcbaa08653a3"
          }
        },
        "32877889617d4b55ba84eaa701946ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11fea400cb35482094e57d59feeb99fa",
            "max": 466021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3d15dc4f55644f4a132a76977c789e5",
            "value": 466021
          }
        },
        "32c63b97b356412abadabc341338525f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2101bff0bdf945e8a70777cb3e11c704",
              "IPY_MODEL_be6fa304dfc24320951b7a55885146c9",
              "IPY_MODEL_3a0a686153ca4cd5b03c75ce5c4ed7f9"
            ],
            "layout": "IPY_MODEL_0f339ebd56024c92abc76e4af9c723bd"
          }
        },
        "3335ae171b9c4514ba146dd1f80bfae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a364a9cf9e3485aaf98d0776bbe5498",
            "placeholder": "​",
            "style": "IPY_MODEL_bc5de9796bda4f7c9120fd7ea72b359f",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "35b7d80a30974ddab219d889613671c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3683dba1a9bb448eb153cb548b2e3b03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36a5a86d54a94b27bc5e36df037d0fe8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "383705f97b7b404b8dc47907c5db1237": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29c960fbfd1c4854b4c382ccb17eef48",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d460d8af99a462fa7542da09cc5871b",
            "value": 116
          }
        },
        "38d2ed6f857e42a1a59307328ac7ba6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a0256002c60456fb02862a53588646c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3683dba1a9bb448eb153cb548b2e3b03",
            "max": 231536,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6042ca8837244dc4a93f42dd8d08e6d0",
            "value": 231536
          }
        },
        "3a0a686153ca4cd5b03c75ce5c4ed7f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ba601eafbc64743a434b4817da3353b",
            "placeholder": "​",
            "style": "IPY_MODEL_6dee24c4e4374c75916c48cef79f8fdc",
            "value": " 571/571 [00:00&lt;00:00, 33.3kB/s]"
          }
        },
        "3b0cae9c02774c1495535eff8bfb2825": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bbce4b4e4934e61b8579010a03ae341": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dba16b5cf2e454085d8f5aa95ca774e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f411b816a624c1fb16dd251bb4e7b9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "400be2a4dc414538bb2b0a27a85e7768": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "407f95a5d9534d59aab305bf4c2f99d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40f914a9eb0c43cb82c383d8af26c54e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4173021814eb494695a17d78860c5bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4466b6fb80d54dd992c2db69aedd7acf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "464cdffb4f1b4c68984edc8e943c0b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "494879bd57914e7f902054dc96f3f70e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3335ae171b9c4514ba146dd1f80bfae5",
              "IPY_MODEL_746fc06feac94a74a506cb11f580000b",
              "IPY_MODEL_ff96fbfd4723499e86b797c4856f0fd4"
            ],
            "layout": "IPY_MODEL_1427470bce6c488a98f92f1f7e71c3ed"
          }
        },
        "4a364a9cf9e3485aaf98d0776bbe5498": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c54c9781c814dfea253ed5ffd850f69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cab9d877ccb48dfb59a34261dd93473": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f886c190c31947e5a5eeed6a3659dbe1",
            "placeholder": "​",
            "style": "IPY_MODEL_a442b2fb2c3041d393b0685a44ddaa76",
            "value": "README.md: 100%"
          }
        },
        "50dd6e4c5c7e47229ddc7bd49232485d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51eb44a43dd543249f72445dc78611cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5258001d87a44ea2baaf5dfa0c9ac6ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5280dc0dbfd44cb68b38ce3fd7ab5bc4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53466d29ffff400294f7ce596128d917": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4b4aff7168c4764a99ac351c4a48b94",
            "placeholder": "​",
            "style": "IPY_MODEL_6d23a2dc763944559834a116b39aec35",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 591kB/s]"
          }
        },
        "53a31390b6404b598f282d76aa1691c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fb03d9e41e44f6cad5df860ee29464c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36a5a86d54a94b27bc5e36df037d0fe8",
            "placeholder": "​",
            "style": "IPY_MODEL_84a1d9b0e98f42d19169c32e8058c437",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6042ca8837244dc4a93f42dd8d08e6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6081002fb30b436d9332c10185253d00": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "641839ad713f46e8acbbdb8874c31866": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb066d3c51dc455c83349c5240e63c9f",
            "placeholder": "​",
            "style": "IPY_MODEL_26c1f6bdb5814b1f8a789077115c6064",
            "value": " 438M/438M [00:05&lt;00:00, 25.1MB/s]"
          }
        },
        "64b7b5079dfd478aad67a64ed65ce4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7cf2e9157f45405fb23c139b1ce7632c",
              "IPY_MODEL_3a0256002c60456fb02862a53588646c",
              "IPY_MODEL_2f7772e31e224e2abd54c7a92739fd6f"
            ],
            "layout": "IPY_MODEL_51eb44a43dd543249f72445dc78611cf"
          }
        },
        "68a0c8cd1ca049fab78f4f8c2503dc45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_987446d5abc54e1ca87f592e4c1e170f",
            "placeholder": "​",
            "style": "IPY_MODEL_01cb43bbc401453bbc59590358b43f0a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "6bc509065ee849d79e8f805a3a08ffdb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d23a2dc763944559834a116b39aec35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6dee24c4e4374c75916c48cef79f8fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e409424203940a48002d50d0e28e6a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "746fc06feac94a74a506cb11f580000b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40f914a9eb0c43cb82c383d8af26c54e",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_198522a4054b4be4a662f5a5993aa18a",
            "value": 53
          }
        },
        "7636e15ce00f447b9381d5747e2fcccd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77640ea0fc8549908007b162e78248ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_400be2a4dc414538bb2b0a27a85e7768",
            "placeholder": "​",
            "style": "IPY_MODEL_ea12981fd3824e1192d4251d85979f19",
            "value": "tokenizer.json: 100%"
          }
        },
        "7cb8708664a84d4fa2be931c0992ed5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cf2e9157f45405fb23c139b1ce7632c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d078311d561c4a74920d8823aa0a444b",
            "placeholder": "​",
            "style": "IPY_MODEL_38d2ed6f857e42a1a59307328ac7ba6a",
            "value": "vocab.txt: 100%"
          }
        },
        "7d460d8af99a462fa7542da09cc5871b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7de6670c31fc42cbb0f4cb9dcd2ebf14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f411b816a624c1fb16dd251bb4e7b9c",
            "max": 10621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de0c678f4cb54774afd1d62283d4cfe4",
            "value": 10621
          }
        },
        "7f0aef7370744e5b8783f0f03bd79b0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f9ebe3075af4ede9106300ccff73ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cab9d877ccb48dfb59a34261dd93473",
              "IPY_MODEL_7de6670c31fc42cbb0f4cb9dcd2ebf14",
              "IPY_MODEL_53466d29ffff400294f7ce596128d917"
            ],
            "layout": "IPY_MODEL_7636e15ce00f447b9381d5747e2fcccd"
          }
        },
        "82470d3aad9b4342aedecb31a79bf967": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "824fec9487534fb29beb9791f9113c42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fb03d9e41e44f6cad5df860ee29464c",
              "IPY_MODEL_b7987270f7cb443683fa7baa1f07a8f3",
              "IPY_MODEL_9c270f2d56fa41c79f02d029fa4d2abc"
            ],
            "layout": "IPY_MODEL_0e63c3f6f4934406ac63a6c2b23d2d46"
          }
        },
        "84a1d9b0e98f42d19169c32e8058c437": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "880020f8ed0d4332a9eaee27b1dbc284": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a523c6cd4ed54c1ea8a34b74c2baee54",
            "placeholder": "​",
            "style": "IPY_MODEL_eeb9655343be4d1daab298a48e56ccd8",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "8ca76586462549978679c4f3857df894": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f0aef7370744e5b8783f0f03bd79b0f",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3ad0a77fcf24ba8b4fc380f7ee7364d",
            "value": 190
          }
        },
        "8d945524f3494f32a73e62b26c4d1c44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e02f7cdeda6401e8a7e6672c6da353a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e90b52280df34d1d9a3858089b3c6c0b",
              "IPY_MODEL_a473df76de9d4c3084cd9d05fd007333",
              "IPY_MODEL_22dcb2860b0748198f6519d67693bada"
            ],
            "layout": "IPY_MODEL_af6a60683b7f429da7a352f86c321ae6"
          }
        },
        "93f5b37935f349a7b11539d5c563dfce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d945524f3494f32a73e62b26c4d1c44",
            "placeholder": "​",
            "style": "IPY_MODEL_f3f0d17edfaf4e8cab19da2a2e0c016e",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "987446d5abc54e1ca87f592e4c1e170f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9baac9d2a18b4dae8c85f3f095695072": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c270f2d56fa41c79f02d029fa4d2abc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e952f7424060456fae42e0ddcb1806fc",
            "placeholder": "​",
            "style": "IPY_MODEL_3b0cae9c02774c1495535eff8bfb2825",
            "value": " 363/363 [00:00&lt;00:00, 15.4kB/s]"
          }
        },
        "a442b2fb2c3041d393b0685a44ddaa76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a473df76de9d4c3084cd9d05fd007333": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e409424203940a48002d50d0e28e6a3",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d24e603b07a8492fbe3a9b0819925bba",
            "value": 349
          }
        },
        "a523c6cd4ed54c1ea8a34b74c2baee54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae9a131048b7467ca4ca9a20703e2def": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b971ca5cee8f41b193798d7c24c6bd95",
              "IPY_MODEL_d407736189a34420bb6e89a3ba88ea11",
              "IPY_MODEL_641839ad713f46e8acbbdb8874c31866"
            ],
            "layout": "IPY_MODEL_6bc509065ee849d79e8f805a3a08ffdb"
          }
        },
        "af6a60683b7f429da7a352f86c321ae6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b007990024ae4dbaaff6987d36dcf5d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b140d71a471a44d6ae6d804e3bce2510": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4ea639277e6449b8b7286a645472740": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7987270f7cb443683fa7baa1f07a8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_407f95a5d9534d59aab305bf4c2f99d2",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb8df2a8e1bf4140810617309cfe21f4",
            "value": 363
          }
        },
        "b84156ad05194f5fbfcd9fddfa53e0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bbce4b4e4934e61b8579010a03ae341",
            "placeholder": "​",
            "style": "IPY_MODEL_35b7d80a30974ddab219d889613671c1",
            "value": " 466k/466k [00:00&lt;00:00, 7.31MB/s]"
          }
        },
        "b971ca5cee8f41b193798d7c24c6bd95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4466b6fb80d54dd992c2db69aedd7acf",
            "placeholder": "​",
            "style": "IPY_MODEL_0362711877ac4f06ab4c4a24ce21f120",
            "value": "model.safetensors: 100%"
          }
        },
        "bc5de9796bda4f7c9120fd7ea72b359f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be6fa304dfc24320951b7a55885146c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53a31390b6404b598f282d76aa1691c3",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_464cdffb4f1b4c68984edc8e943c0b72",
            "value": 571
          }
        },
        "bf4369e32db041c8a81fe28e8641b80c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c218174a7afc4a719e976c6d316c2744": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93f5b37935f349a7b11539d5c563dfce",
              "IPY_MODEL_383705f97b7b404b8dc47907c5db1237",
              "IPY_MODEL_242084c4a34047888c3bf19d4630cae1"
            ],
            "layout": "IPY_MODEL_b4ea639277e6449b8b7286a645472740"
          }
        },
        "c3ad0a77fcf24ba8b4fc380f7ee7364d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce4e2c4323c840248030bd6b789dd549": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f86899986a50431db7abbe09afe97d67",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7e3c121b6534ea68fef30e3118bcb0f",
            "value": 239
          }
        },
        "d078311d561c4a74920d8823aa0a444b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d24e603b07a8492fbe3a9b0819925bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d407736189a34420bb6e89a3ba88ea11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf4369e32db041c8a81fe28e8641b80c",
            "max": 437971872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4173021814eb494695a17d78860c5bd1",
            "value": 437971872
          }
        },
        "d4b4aff7168c4764a99ac351c4a48b94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7e3c121b6534ea68fef30e3118bcb0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de0c678f4cb54774afd1d62283d4cfe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3d15dc4f55644f4a132a76977c789e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e90b52280df34d1d9a3858089b3c6c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11f728342557489c9d4a816a72dc74ae",
            "placeholder": "​",
            "style": "IPY_MODEL_217650c1965f49bdb61b385155ab634e",
            "value": "modules.json: 100%"
          }
        },
        "e952f7424060456fae42e0ddcb1806fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea12981fd3824e1192d4251d85979f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eeb9655343be4d1daab298a48e56ccd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0a907c9ac6b4cb4a4d5bcbaa08653a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3f0d17edfaf4e8cab19da2a2e0c016e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f85dd60965154b29a61229ef9a609e88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f86899986a50431db7abbe09afe97d67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f886c190c31947e5a5eeed6a3659dbe1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f92ce6be8e784b7a98ca8798c958ddd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb066d3c51dc455c83349c5240e63c9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb8df2a8e1bf4140810617309cfe21f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff96fbfd4723499e86b797c4856f0fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f85dd60965154b29a61229ef9a609e88",
            "placeholder": "​",
            "style": "IPY_MODEL_1783b769c2b447278fc931a8d936ddbd",
            "value": " 53.0/53.0 [00:00&lt;00:00, 2.79kB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
